#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„é…ç½®è¯Šæ–­å·¥å…·
"""

import os
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def print_section(title):
    """æ‰“å°åˆ†èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*70}")
    print(f"  {title}")
    print(f"{'='*70}")

def check_var(name, value, required=True):
    """æ£€æŸ¥å•ä¸ªç¯å¢ƒå˜é‡"""
    if value:
        # éšè—æ•æ„Ÿä¿¡æ¯
        if 'KEY' in name or 'PASSWORD' in name:
            display = value[:10] + '...' if len(value) > 10 else '***'
        else:
            display = value
        status = "âœ…"
        print(f"{status} {name:25s} = {display}")
        return True
    else:
        status = "âŒ" if required else "âš ï¸ "
        print(f"{status} {name:25s} = æœªè®¾ç½®")
        return not required

def main():
    print("\n" + "="*70)
    print("  RAG ç³»ç»Ÿé…ç½®è¯Šæ–­å·¥å…·")
    print("="*70)
    
    all_ok = True
    
    # 1. LLM é…ç½®
    print_section("LLM é…ç½®ï¼ˆç”¨äºæ–‡æœ¬ç”Ÿæˆå’Œå®ä½“æå–ï¼‰")
    llm_model = os.getenv('CLOUD_MODEL')
    llm_key = os.getenv('CLOUD_API_KEY')
    llm_url = os.getenv('CLOUD_BASE_URL')
    
    all_ok &= check_var('CLOUD_MODEL', llm_model)
    all_ok &= check_var('CLOUD_API_KEY', llm_key)
    all_ok &= check_var('CLOUD_BASE_URL', llm_url)
    
    if llm_model:
        print(f"\nğŸ’¡ å½“å‰ LLM æ¨¡å‹: {llm_model}")
        if 'qwen' in llm_model.lower():
            print("   â„¹ï¸  æ£€æµ‹åˆ° Qwen æ¨¡å‹")
            print("   âš ï¸  ç¡®ä¿ä½ çš„ API ç«¯ç‚¹æ”¯æŒæ­¤æ¨¡å‹")
        elif 'deepseek' in llm_model.lower():
            print("   â„¹ï¸  æ£€æµ‹åˆ° DeepSeek æ¨¡å‹")
        elif 'gpt' in llm_model.lower():
            print("   â„¹ï¸  æ£€æµ‹åˆ° OpenAI GPT æ¨¡å‹")
        
        if 'vl' in llm_model.lower() or 'vision' in llm_model.lower():
            print("   â„¹ï¸  è¿™æ˜¯ä¸€ä¸ª Vision æ¨¡å‹ï¼Œæ”¯æŒå›¾åƒå¤„ç†")
    
    # 2. Vision Model é…ç½®
    print_section("Vision Model é…ç½®ï¼ˆç”¨äºå›¾åƒã€è¡¨æ ¼å¤„ç†ï¼‰")
    vision_model = os.getenv('VISION_MODEL')
    vision_key = os.getenv('VISION_API_KEY')
    vision_url = os.getenv('VISION_BASE_URL')
    
    if vision_model:
        check_var('VISION_MODEL', vision_model, required=False)
        check_var('VISION_API_KEY', vision_key, required=False)
        check_var('VISION_BASE_URL', vision_url, required=False)
        print(f"\nğŸ’¡ ä½¿ç”¨ç‹¬ç«‹çš„ Vision æ¨¡å‹: {vision_model}")
    else:
        print("âš ï¸  VISION_MODEL æœªè®¾ç½®")
        print(f"ğŸ’¡ å°†ä½¿ç”¨ LLM æ¨¡å‹å¤„ç†å›¾åƒ: {llm_model}")
        if llm_model and 'vl' not in llm_model.lower() and 'vision' not in llm_model.lower():
            print("   âš ï¸  è­¦å‘Š: è¯¥ LLM æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå›¾åƒå¤„ç†")
            print("   å»ºè®®è®¾ç½®æ”¯æŒ vision çš„æ¨¡å‹ï¼Œä¾‹å¦‚:")
            print("      export VISION_MODEL='gpt-4o'")
    
    # 3. Embedding é…ç½®
    print_section("Embedding é…ç½®ï¼ˆç”¨äºå‘é‡åŒ–æ–‡æ¡£ï¼‰")
    emb_model = os.getenv('OPENAI_API_MODEL')
    emb_key = os.getenv('OPENAI_API_KEY')
    emb_url = os.getenv('OPENAI_BASE_URL')
    
    all_ok &= check_var('OPENAI_API_MODEL', emb_model)
    all_ok &= check_var('OPENAI_API_KEY', emb_key)
    all_ok &= check_var('OPENAI_BASE_URL', emb_url)
    
    if emb_model:
        print(f"\nğŸ’¡ Embedding æ¨¡å‹: {emb_model}")
        dim_map = {
            'text-embedding-3-large': 3072,
            'text-embedding-3-small': 1536,
            'text-embedding-ada-002': 1536,
            'bge-m3': 1024,
        }
        for key, dim in dim_map.items():
            if key in emb_model:
                print(f"   å‘é‡ç»´åº¦: {dim}")
                break
    
    # 4. HuggingFace é…ç½®
    print_section("HuggingFace é…ç½®ï¼ˆç”¨äºä¸‹è½½æ¨¡å‹ï¼‰")
    hf_endpoint = os.getenv('HF_ENDPOINT')
    check_var('HF_ENDPOINT', hf_endpoint, required=False)
    if not hf_endpoint:
        print("   å»ºè®®è®¾ç½®: export HF_ENDPOINT=https://hf-mirror.com")
    
    # 5. é…ç½®ä¸€è‡´æ€§æ£€æŸ¥
    print_section("é…ç½®ä¸€è‡´æ€§æ£€æŸ¥")
    
    issues = []
    
    # æ£€æŸ¥ API URL æ˜¯å¦åŒ¹é…
    if llm_url and emb_url and llm_url == emb_url:
        print("âœ… LLM å’Œ Embedding ä½¿ç”¨ç›¸åŒçš„ API ç«¯ç‚¹")
        if llm_key != emb_key:
            issues.append("âš ï¸  LLM å’Œ Embedding ä½¿ç”¨ç›¸åŒç«¯ç‚¹ä½†ä¸åŒçš„ API Key")
    else:
        print("â„¹ï¸  LLM å’Œ Embedding ä½¿ç”¨ä¸åŒçš„ API ç«¯ç‚¹ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼‰")
    
    # æ£€æŸ¥æ¨¡å‹åç§°
    if llm_model:
        if 'qwen' in llm_model.lower():
            if 'siliconflow' not in str(llm_url).lower() and 'dashscope' not in str(llm_url).lower():
                issues.append(f"âš ï¸  Qwen æ¨¡å‹é€šå¸¸éœ€è¦ç‰¹å®šçš„ API ç«¯ç‚¹")
                issues.append(f"   å½“å‰ URL: {llm_url}")
                issues.append(f"   ç¡®è®¤æ­¤ç«¯ç‚¹æ”¯æŒ: {llm_model}")
    
    if issues:
        print("\nå‘ç°æ½œåœ¨é—®é¢˜:")
        for issue in issues:
            print(f"  {issue}")
    else:
        print("âœ… æœªå‘ç°æ˜æ˜¾çš„é…ç½®å†²çª")
    
    # 6. æ¨èé…ç½®
    print_section("æ¨èé…ç½®ç¤ºä¾‹")
    
    print("\næ–¹æ¡ˆ 1: DeepSeek + OpenAI (æ¨è)")
    print("-" * 70)
    print("# LLM ç”¨ DeepSeekï¼ˆä¾¿å®œï¼‰")
    print("export CLOUD_MODEL='deepseek-chat'")
    print("export CLOUD_API_KEY='sk-your-deepseek-key'")
    print("export CLOUD_BASE_URL='https://api.deepseek.com/v1'")
    print()
    print("# Vision ç”¨ OpenAI gpt-4o-miniï¼ˆæ”¯æŒå›¾åƒï¼‰")
    print("export VISION_MODEL='gpt-4o-mini'")
    print("export VISION_API_KEY='sk-your-openai-key'")
    print("export VISION_BASE_URL='https://api.openai.com/v1'")
    print()
    print("# Embedding ç”¨ OpenAI")
    print("export OPENAI_API_KEY='sk-your-openai-key'")
    print("export OPENAI_BASE_URL='https://api.openai.com/v1'")
    print("export OPENAI_API_MODEL='text-embedding-3-large'")
    
    print("\næ–¹æ¡ˆ 2: å…¨éƒ¨ OpenAI")
    print("-" * 70)
    print("export CLOUD_MODEL='gpt-4o-mini'")
    print("export CLOUD_API_KEY='sk-your-openai-key'")
    print("export CLOUD_BASE_URL='https://api.openai.com/v1'")
    print("export OPENAI_API_KEY='sk-your-openai-key'")
    print("export OPENAI_BASE_URL='https://api.openai.com/v1'")
    print("export OPENAI_API_MODEL='text-embedding-3-large'")
    
    if llm_model and 'qwen' in llm_model.lower():
        print("\næ–¹æ¡ˆ 3: å½“å‰ Qwen é…ç½®ï¼ˆç¡®ä¿ API æ­£ç¡®ï¼‰")
        print("-" * 70)
        print(f"export CLOUD_MODEL='{llm_model}'")
        print(f"export CLOUD_API_KEY='your-api-key'")
        print(f"export CLOUD_BASE_URL='{llm_url}'  # ç¡®ä¿æ­¤ API æ”¯æŒ {llm_model}")
        print()
        print("# å¦‚æœ Qwen ä¸æ”¯æŒ visionï¼Œéœ€è¦å•ç‹¬é…ç½®")
        print("export VISION_MODEL='gpt-4o-mini'  # æˆ–å…¶ä»–æ”¯æŒ vision çš„æ¨¡å‹")
        print("export VISION_API_KEY='sk-openai-key'")
        print("export VISION_BASE_URL='https://api.openai.com/v1'")
    
    # æ€»ç»“
    print_section("è¯Šæ–­æ€»ç»“")
    
    if all_ok:
        print("âœ… æ‰€æœ‰å¿…éœ€çš„ç¯å¢ƒå˜é‡å·²é…ç½®")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. æµ‹è¯• API: python test_api.py")
        print("  2. è¿è¡Œç³»ç»Ÿ: python rag_qa_agent.py")
    else:
        print("âŒ å‘ç°é…ç½®é—®é¢˜")
        print("\nè¯·æ‰§è¡Œ:")
        print("  1. ç¼–è¾‘ env.sh: nano env.sh")
        print("  2. é‡æ–°åŠ è½½: source env.sh")
        print("  3. é‡æ–°è¯Šæ–­: python diagnose.py")
    
    print("\n" + "="*70)
    
    return 0 if all_ok else 1

if __name__ == "__main__":
    sys.exit(main())

