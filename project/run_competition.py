#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
@File    :   run_competition.py
@Time    :   2025/11/15
@Desc    :   ç«èµ›è¿è¡Œè„šæœ¬ - å¤„ç†æ‰€æœ‰é¢˜ç›®å¹¶ç”Ÿæˆæäº¤æ–‡ä»¶
'''

import json
import os
from typing import List, Dict
from VectorBase import VectorStore
from LLM import OpenAIChat
from Embeddings import OpenAIEmbedding
from agent import RAGAgent
from enhanced_utils import EnhancedReadFiles
from tqdm import tqdm


# åˆèµ›ä¸€æœŸé¢˜ç›®
COMPETITION_QUESTIONS = {
    "åŸºç¡€é¢˜": [
        "2024 å¹´ï¼Œæ ªæ´²ä¸­è½¦æ—¶ä»£ç”µæ°”è‚¡ä»½æœ‰é™å…¬å¸ä¸­æ ‡é‡‘é¢æ˜¯å¤šå°‘ï¼Ÿ",
        "æ ¹æ®æ¬§æ´²é“è·¯å±€ 2025-2027 å¹´å•ä¸€è§„åˆ’æ–‡ä»¶ï¼Œæœºæ„æ³¨å†Œç³»ç»Ÿè¿ç§»åˆ°çŸ¥è¯†å›¾è°±ï¼ˆknowledge graphï¼‰æ–¹æ³•çš„ç›®æ ‡è¿›åº¦åœ¨ 2025 å¹´åº•åº”è¾¾åˆ°å¤šå°‘ç™¾åˆ†æ¯”ï¼Ÿ",
        "åœ¨ UIC çš„æŠ¥å‘Šé‡Œï¼Œæ ¹æ®å›½é™…èƒ½æºç½²çš„åˆ†æï¼Œé“è·¯çš„å¸‚åœºä»½é¢éœ€è¦å¢é•¿å¤šå°‘æ‰èƒ½åœ¨æœ¬åå¹´å†…å®ç°ã€Šå·´é»åå®šã€‹çš„ç›®æ ‡",
        "å‚ç…§ IEEE 1474.1 çš„å®šä¹‰ï¼Œé™„ä»¶ D (Typical safe braking model) ä¸­å¯¹å®‰å…¨åˆ¶åŠ¨æ¨¡å‹çš„æè¿°ï¼Œåœ¨"æ»‘è¡Œæ—¶é—´ (Coast time, C)"æœŸé—´ï¼Œåˆ—è½¦è¢«å‡å®šå¤„äºä»€ä¹ˆçŠ¶æ€ï¼Ÿ",
        "åœ¨ Manresa è½¦ç«™çš„äº‹ä»¶è°ƒæŸ¥æŠ¥å‘Šä¸­ï¼Œåˆ—è½¦ 78443 è¢«æˆæƒè¶Šè¿‡ 3023 è¿›ç«™ä¿¡å·æœºåï¼Œä½•æ—¶ï¼ˆæ—¥æœŸå’Œæ—¶é—´ï¼‰å‘ç”Ÿäº†åˆ—è½¦ 95218 æœ€ç»ˆå¯åŠ¨äº†è¡Œé©¶ï¼Œå¹¶æœ€ç»ˆå¯¼è‡´ä¸¤åˆ—è½¦å­˜åœ¨ç¢°æ’é£é™©ï¼Ÿ"
    ],
    "ä¸­çº§é¢˜": [
        "å—äº¬åœ°é“ S7 å·çº¿çš„è¿è¥é‡Œç¨‹ï¼Œåœ¨æ±Ÿè‹çœå†…å·²è¿è¥åœ°é“é•¿åº¦ä¸­æ’ç¬¬å‡ ï¼Ÿ",
        "è½¦è¾†å¤–éƒ¨ç§»åŠ¨å®ä½“çš„åœºæ™¯è¦ç´ ï¼šæ ¹æ® GB/T 43267â€”2023ï¼ˆé¢„æœŸåŠŸèƒ½å®‰å…¨ï¼‰ï¼Œåœ¨åœºæ™¯è¦ç´ ç»“æ„ä¸­ï¼Œå¯ç§»åŠ¨å®ä½“çš„ç¬¬ 2 å±‚è¦ç´ å’Œç¬¬ 3 å±‚è¦ç´ åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆéœ€å®Œæ•´åˆ—å‡ºç¬¬ 3 å±‚ä¸­æ‰€æœ‰å®ä½“ç±»å‹ï¼‰ã€‚",
        "æ ¹æ®æ–‡æ¡£ã€Š2024_Communications-Based Train Controlã€‹ï¼Œå›¾ 5.11 æ‰€ç¤ºçš„ç½‘çŠ¶æ§åˆ¶å›è·¯ç»“æ„ï¼ŒATO å­ç³»ç»Ÿæ˜¯å¦‚ä½•å®ç°è‡ªèº«çš„æ§åˆ¶å›è·¯çš„ï¼Ÿè¯·é˜è¿°å…¶å¦‚ä½•è·å–è¾“å…¥ï¼ˆMessgliederï¼‰ï¼Œå¦‚ä½•å½¢æˆè½¦è¾†è½¨è¿¹ï¼ˆFahrzeugtrajektorieï¼‰ï¼Œä»¥åŠå¦‚ä½•å°†è½¨è¿¹ä½œä¸ºç›®æ ‡å€¼ä¼ é€’ç»™åˆ—è½¦çš„æ§åˆ¶è®¾å¤‡ï¼ˆSteuergerÃ¤tï¼‰ã€‚"
    ],
    "é«˜çº§é¢˜": [
        "åœ¨ CBTC äº’è”äº’é€šè§„èŒƒä½“ç³»ä¸­ï¼Œå…³äºåˆ—è½¦å¯åŠ¨ã€åŠ é€Ÿã€å·¡èˆªå’Œåˆ¶åŠ¨çš„è‡ªåŠ¨æ§åˆ¶åŠŸèƒ½ï¼Œå…¶åœ¨ã€Šç³»ç»Ÿæ€»ä½“è¦æ±‚ã€‹ä¸­çš„åˆ†é…å½’å±äºå“ªä¸ªå­ç³»ç»Ÿï¼Ÿå¹¶åœ¨ã€ŠCBTC éƒ¨åˆ†æµ‹è¯•åŠéªŒè¯ã€‹ä¸­ä½“ç°åœ¨å“ªä¸ªåŠŸèƒ½çš„æµ‹è¯•ä¸­ï¼Œæµ‹è¯•éœ€æ±‚ç¼–å·æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ERTMS/ETCS åˆ—è½¦ç‰µå¼•ç³»ç»Ÿæ•°æ®å®šä¹‰æ¼”å˜ï¼š æ¯”è¾ƒ SUBSET-026 Baseline 3 (v3.4.0) å’Œ Baseline 4 (v4.0.0) ç‰ˆæœ¬ä¸­ Validated Train Data (Packet 11) çš„å†…å®¹å®šä¹‰ï¼š1ï¼‰è¯·æŒ‡å‡ºè¯¥æ•°æ®åŒ…ä¸­ç”¨äºè¡¨ç¤ºç‰µå¼•ç³»ç»Ÿæ ‡è¯†çš„å˜é‡åç§°ï¼Ÿ2ï¼‰å½“è¯¥å˜é‡ä¸ä¸ºé›¶æ—¶ï¼Œéœ€è¦åŒ…å«å“ªäº›é¢å¤–çš„ç‰µå¼•æ•°æ®å˜é‡ï¼Ÿ"
    ]
}


class CompetitionRunner:
    """
    ç«èµ›è¿è¡Œå™¨
    """
    
    def __init__(self, data_path: str = '../data', storage_path: str = 'storage'):
        self.data_path = data_path
        self.storage_path = storage_path
        self.vector_store = None
        self.agent = None
        
    def build_or_load_vectorstore(self, rebuild: bool = False):
        """
        æ„å»ºæˆ–åŠ è½½å‘é‡æ•°æ®åº“
        """
        print("=" * 60)
        if rebuild or not os.path.exists(f"{self.storage_path}/vectors.json"):
            print("ğŸ“š æ„å»ºå‘é‡æ•°æ®åº“...")
            # ä½¿ç”¨å¢å¼ºçš„æ–‡æ¡£è¯»å–å™¨
            reader = EnhancedReadFiles(self.data_path)
            docs = reader.get_content(max_token_len=400, cover_content=50)
            print(f"   æ€»å…±åˆ†å—æ•°: {len(docs)}")
            
            # åˆ›å»ºå‘é‡å­˜å‚¨
            self.vector_store = VectorStore(docs)
            embedding = OpenAIEmbedding()
            
            print("   ç”Ÿæˆå‘é‡åµŒå…¥...")
            self.vector_store.get_vector(EmbeddingModel=embedding)
            
            print("   ä¿å­˜å‘é‡æ•°æ®åº“...")
            self.vector_store.persist(path=self.storage_path)
            print("âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼")
        else:
            print("ğŸ“‚ åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“...")
            self.vector_store = VectorStore()
            self.vector_store.load_vector(self.storage_path)
            print(f"âœ… åŠ è½½å®Œæˆï¼æ–‡æ¡£æ•°é‡: {len(self.vector_store.document)}")
        print("=" * 60 + "\n")
    
    def initialize_agent(self):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“
        """
        embedding = OpenAIEmbedding()
        llm = OpenAIChat()
        self.agent = RAGAgent(self.vector_store, llm, embedding)
        print("ğŸ¤– æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆï¼\n")
    
    def process_single_question(self, query: str, question_type: str = "") -> Dict:
        """
        å¤„ç†å•ä¸ªé—®é¢˜
        """
        print(f"\n{'='*60}")
        print(f"é—®é¢˜ç±»å‹: {question_type}")
        print(f"é—®é¢˜: {query}")
        print(f"{'='*60}")
        
        result = self.agent.query_with_retry(query)
        output = self.agent.format_output(result)
        
        print(f"\nç­”æ¡ˆ: {output['answer']}")
        print(f"æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µæ•°: {len(output['result'])}")
        
        return output
    
    def process_all_questions(self, output_dir: str = 'outputs'):
        """
        å¤„ç†æ‰€æœ‰é¢˜ç›®å¹¶ä¿å­˜ç»“æœ
        """
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        all_results = []
        
        for question_type, questions in COMPETITION_QUESTIONS.items():
            print(f"\n\n{'#'*60}")
            print(f"# å¼€å§‹å¤„ç†: {question_type} (å…± {len(questions)} é“)")
            print(f"{'#'*60}\n")
            
            for idx, question in enumerate(questions, 1):
                try:
                    result = self.process_single_question(question, f"{question_type}-{idx}")
                    
                    # ä¿å­˜å•ä¸ªç»“æœ
                    output_file = os.path.join(output_dir, f"{question_type}_{idx}.json")
                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(result, f, ensure_ascii=False, indent=2)
                    
                    all_results.append({
                        'type': question_type,
                        'index': idx,
                        'result': result
                    })
                    
                    print(f"âœ… å·²ä¿å­˜åˆ°: {output_file}\n")
                    
                except Exception as e:
                    print(f"âŒ å¤„ç†å‡ºé”™: {e}\n")
                    continue
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_file = os.path.join(output_dir, 'all_results.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        
        print(f"\n{'='*60}")
        print(f"ğŸ‰ æ‰€æœ‰é¢˜ç›®å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        print(f"ğŸ“Š æ±‡æ€»æ–‡ä»¶: {summary_file}")
        print(f"{'='*60}\n")
        
        return all_results
    
    def run_interactive_mode(self):
        """
        äº¤äº’æ¨¡å¼ - å¯ä»¥è¾“å…¥è‡ªå®šä¹‰é—®é¢˜
        """
        print("\n" + "="*60)
        print("ğŸ¯ è¿›å…¥äº¤äº’æ¨¡å¼")
        print("è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢ï¼Œè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("="*60 + "\n")
        
        while True:
            try:
                query = input("\nè¯·è¾“å…¥é—®é¢˜: ").strip()
                
                if query.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ é€€å‡ºäº¤äº’æ¨¡å¼")
                    break
                
                if not query:
                    continue
                
                result = self.process_single_question(query, "è‡ªå®šä¹‰")
                
                # è¯¢é—®æ˜¯å¦ä¿å­˜
                save = input("\næ˜¯å¦ä¿å­˜ç»“æœï¼Ÿ(y/n): ").strip().lower()
                if save == 'y':
                    filename = input("è¯·è¾“å…¥æ–‡ä»¶å (ä¸å«æ‰©å±•å): ").strip()
                    if filename:
                        output_file = f"outputs/{filename}.json"
                        os.makedirs('outputs', exist_ok=True)
                        with open(output_file, 'w', encoding='utf-8') as f:
                            json.dump(result, f, ensure_ascii=False, indent=2)
                        print(f"âœ… å·²ä¿å­˜åˆ°: {output_file}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ é€€å‡ºäº¤äº’æ¨¡å¼")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†å‡ºé”™: {e}")
                continue


def main():
    """
    ä¸»å‡½æ•°
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='æ™ºèƒ½ä½“ç«èµ›è¿è¡Œè„šæœ¬')
    parser.add_argument('--mode', type=str, default='all', 
                       choices=['all', 'interactive', 'single'],
                       help='è¿è¡Œæ¨¡å¼: all(å¤„ç†æ‰€æœ‰é¢˜ç›®), interactive(äº¤äº’æ¨¡å¼), single(å•ä¸ªé—®é¢˜)')
    parser.add_argument('--rebuild', action='store_true',
                       help='é‡æ–°æ„å»ºå‘é‡æ•°æ®åº“')
    parser.add_argument('--query', type=str, default='',
                       help='å•ä¸ªé—®é¢˜æ¨¡å¼ä¸‹çš„æŸ¥è¯¢')
    parser.add_argument('--data-path', type=str, default='../data',
                       help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--storage-path', type=str, default='storage',
                       help='å‘é‡æ•°æ®åº“å­˜å‚¨è·¯å¾„')
    parser.add_argument('--output-dir', type=str, default='outputs',
                       help='è¾“å‡ºç›®å½•è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¿è¡Œå™¨
    runner = CompetitionRunner(
        data_path=args.data_path,
        storage_path=args.storage_path
    )
    
    # æ„å»ºæˆ–åŠ è½½å‘é‡æ•°æ®åº“
    runner.build_or_load_vectorstore(rebuild=args.rebuild)
    
    # åˆå§‹åŒ–æ™ºèƒ½ä½“
    runner.initialize_agent()
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œ
    if args.mode == 'all':
        runner.process_all_questions(output_dir=args.output_dir)
    elif args.mode == 'interactive':
        runner.run_interactive_mode()
    elif args.mode == 'single':
        if not args.query:
            print("âŒ å•ä¸ªé—®é¢˜æ¨¡å¼éœ€è¦æä¾› --query å‚æ•°")
            return
        result = runner.process_single_question(args.query, "å•ä¸ªé—®é¢˜")
        
        # ä¿å­˜ç»“æœ
        os.makedirs(args.output_dir, exist_ok=True)
        output_file = os.path.join(args.output_dir, 'single_query_result.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    main()

