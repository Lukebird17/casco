#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
@File    :   advanced_ocr_system.py
@Time    :   2025/11/16
@Desc    :   é«˜çº§OCRç³»ç»Ÿ - æ”¯æŒè¡¨æ ¼ã€å¤šè¯­è¨€ã€æ°´å°å¤„ç†ã€å…¬å¼è¯†åˆ«ç­‰
'''

import os
import cv2
import numpy as np
from typing import Dict, List, Tuple, Optional
from PIL import Image
import io


class ImagePreprocessor:
    """å›¾åƒé¢„å¤„ç†å™¨ - å¤„ç†æ—‹è½¬ã€æ°´å°ã€æ¨¡ç³Šç­‰é—®é¢˜"""
    
    @staticmethod
    def detect_and_rotate(image: np.ndarray) -> np.ndarray:
        """
        æ£€æµ‹å›¾ç‰‡æ–¹å‘å¹¶è‡ªåŠ¨æ—‹è½¬
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆnumpyæ•°ç»„ï¼‰
        Returns:
            æ—‹è½¬åçš„å›¾åƒ
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # æ£€æµ‹æ–‡æœ¬æ–¹å‘ï¼ˆä½¿ç”¨è¾¹ç¼˜æ£€æµ‹ï¼‰
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)
        
        if lines is not None:
            angles = []
            for line in lines:
                x1, y1, x2, y2 = line[0]
                angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
                angles.append(angle)
            
            # è®¡ç®—å¹³å‡è§’åº¦
            median_angle = np.median(angles)
            
            # å¦‚æœè§’åº¦æ˜æ˜¾åç¦»ï¼Œè¿›è¡Œæ—‹è½¬
            if abs(median_angle) > 5:
                print(f"  ğŸ”„ æ£€æµ‹åˆ°å›¾ç‰‡å€¾æ–œ {median_angle:.1f}Â°ï¼Œæ­£åœ¨æ—‹è½¬...")
                height, width = image.shape[:2]
                center = (width // 2, height // 2)
                rotation_matrix = cv2.getRotationMatrix2D(center, -median_angle, 1.0)
                image = cv2.warpAffine(image, rotation_matrix, (width, height), 
                                      flags=cv2.INTER_CUBIC, 
                                      borderMode=cv2.BORDER_REPLICATE)
        
        return image
    
    @staticmethod
    def remove_watermark(image: np.ndarray, method: str = 'auto') -> np.ndarray:
        """
        å»é™¤æ°´å°
        Args:
            image: è¾“å…¥å›¾åƒ
            method: å»é™¤æ–¹æ³•ï¼ˆ'auto', 'threshold', 'inpaint'ï¼‰
        Returns:
            å»æ°´å°åçš„å›¾åƒ
        """
        print("  ğŸ¨ æ­£åœ¨å»é™¤æ°´å°...")
        
        if method == 'threshold':
            # æ–¹æ³•1ï¼šé˜ˆå€¼æ³•ï¼ˆé€‚ç”¨äºæµ…è‰²æ°´å°ï¼‰
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
            _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
            
            # æ‰¾åˆ°æ°´å°åŒºåŸŸ
            kernel = np.ones((5, 5), np.uint8)
            mask = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
            mask = cv2.bitwise_not(mask)
            
            # ä¿®å¤æ°´å°åŒºåŸŸ
            result = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)
            return result
            
        elif method == 'auto':
            # æ–¹æ³•2ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶å»é™¤ï¼ˆç®€å•çš„å¯¹æ¯”åº¦å¢å¼ºï¼‰
            # å¯¹äºè½»å¾®æ°´å°ï¼Œå¢å¼ºå¯¹æ¯”åº¦å¯ä»¥æ”¹å–„è¯†åˆ«
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB) if len(image.shape) == 3 else cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHEï¼ˆå¯¹æ¯”åº¦é™åˆ¶è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡ï¼‰
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            
            enhanced = cv2.merge([l, a, b])
            result = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
            return result
        
        return image
    
    @staticmethod
    def enhance_blurry_image(image: np.ndarray) -> np.ndarray:
        """
        å¢å¼ºæ¨¡ç³Šå›¾åƒ
        Args:
            image: è¾“å…¥å›¾åƒ
        Returns:
            å¢å¼ºåçš„å›¾åƒ
        """
        print("  âœ¨ å¢å¼ºæ¨¡ç³Šå›¾åƒ...")
        
        # 1. é”åŒ–
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]])
        sharpened = cv2.filter2D(image, -1, kernel)
        
        # 2. å»å™ª
        denoised = cv2.fastNlMeansDenoisingColored(sharpened, None, 10, 10, 7, 21) if len(image.shape) == 3 else cv2.fastNlMeansDenoising(sharpened, None, 10, 7, 21)
        
        # 3. å¯¹æ¯”åº¦å¢å¼º
        lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB) if len(image.shape) == 3 else cv2.cvtColor(cv2.cvtColor(denoised, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        enhanced = cv2.merge([l, a, b])
        result = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
        
        return result
    
    @staticmethod
    def detect_blur(image: np.ndarray) -> float:
        """
        æ£€æµ‹å›¾åƒæ¨¡ç³Šåº¦
        Args:
            image: è¾“å…¥å›¾åƒ
        Returns:
            æ¨¡ç³Šåº¦åˆ†æ•°ï¼ˆè¶Šä½è¶Šæ¨¡ç³Šï¼‰
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        return laplacian_var


class AdvancedTableExtractor:
    """é«˜çº§è¡¨æ ¼æå–å™¨ - æ”¯æŒåˆå¹¶å•å…ƒæ ¼çš„å¤æ‚è¡¨æ ¼"""
    
    # å…¨å±€å•ä¾‹
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if AdvancedTableExtractor._initialized:
            return
        
        self.table_engine = None
        self._init_table_engine()
        AdvancedTableExtractor._initialized = True
    
    def _init_table_engine(self):
        """åˆå§‹åŒ–è¡¨æ ¼è¯†åˆ«å¼•æ“"""
        try:
            # PaddleOCR 3.0ä½¿ç”¨PPStructureV3è¿›è¡Œè¡¨æ ¼è¯†åˆ«
            from paddleocr import PPStructureV3
            self.table_engine = PPStructureV3(
                use_doc_orientation_classify=False,
                use_doc_unwarping=False
            )
            print("âœ… è¡¨æ ¼æå–å™¨åˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨PPStructureV3ï¼‰")
        except ImportError:
            print("âš ï¸  PPStructureV3ä¸å¯ç”¨ï¼Œè¡¨æ ¼è¯†åˆ«åŠŸèƒ½å°†è¢«ç¦ç”¨")
            self.table_engine = None
        except Exception as e:
            print(f"âš ï¸  è¡¨æ ¼å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.table_engine = None
    
    def extract_table_with_merged_cells(self, image: np.ndarray, page_num: int = 0) -> List[Dict]:
        """
        æå–åŒ…å«åˆå¹¶å•å…ƒæ ¼çš„å¤æ‚è¡¨æ ¼
        Args:
            image: å›¾åƒæ•°ç»„
            page_num: é¡µç 
        Returns:
            è¡¨æ ¼åˆ—è¡¨
        """
        tables = []
        
        if self.table_engine is None:
            return tables
        
        try:
            print(f"  ğŸ“Š ä½¿ç”¨PPStructureV3è¯†åˆ«è¡¨æ ¼...")
            
            # ä¿å­˜å›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆPPStructureV3éœ€è¦æ–‡ä»¶è·¯å¾„ï¼‰
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                tmp_path = tmp_file.name
                cv2.imwrite(tmp_path, image)
            
            # ä½¿ç”¨PPStructureV3çš„predictæ–¹æ³•
            result = self.table_engine.predict(input=tmp_path)
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.unlink(tmp_path)
            
            # è§£æç»“æœ - PPStructureV3è¿”å›ç»“æœå¯¹è±¡åˆ—è¡¨
            if result:
                for i, res in enumerate(result):
                    # å°è¯•ä»ç»“æœå¯¹è±¡ä¸­æå–è¡¨æ ¼ä¿¡æ¯
                    # ç»“æœå¯èƒ½åŒ…å«layout_parsing_resultç­‰å±æ€§
                    if hasattr(res, 'layout_parsing_result'):
                        layout_result = res.layout_parsing_result
                        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…è¿”å›çš„æ•°æ®ç»“æ„æ¥è§£æ
                        # æš‚æ—¶ç®€å•è®°å½•æ£€æµ‹åˆ°è¡¨æ ¼
                        tables.append({
                            'page': page_num,
                            'table_index': i + 1,
                            'detected': True,
                            'raw_result': str(res)
                        })
            
            if tables:
                print(f"  âœ… è¯†åˆ«åˆ° {len(tables)} ä¸ªè¡¨æ ¼åŒºåŸŸ")
            else:
                print(f"  â„¹ï¸  æœªæ£€æµ‹åˆ°è¡¨æ ¼")
                
        except Exception as e:
            print(f"  âš ï¸  è¡¨æ ¼æå–å‡ºé”™: {e}")
        
        return tables
    
    def _detect_merged_cells(self, html: str) -> bool:
        """æ£€æµ‹æ˜¯å¦åŒ…å«åˆå¹¶å•å…ƒæ ¼"""
        return 'colspan' in html or 'rowspan' in html
    
    def _parse_html_table(self, html: str) -> List[List[str]]:
        """è§£æHTMLè¡¨æ ¼ä¸ºäºŒç»´æ•°ç»„"""
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html, 'html.parser')
        table = soup.find('table')
        
        if not table:
            return []
        
        data = []
        for row in table.find_all('tr'):
            row_data = []
            for cell in row.find_all(['td', 'th']):
                text = cell.get_text(strip=True)
                colspan = int(cell.get('colspan', 1))
                
                # å¤„ç†åˆå¹¶å•å…ƒæ ¼
                row_data.append(text)
                for _ in range(colspan - 1):
                    row_data.append('')
            
            data.append(row_data)
        
        return data
    
    def _html_to_markdown(self, html: str) -> str:
        """å°†HTMLè¡¨æ ¼è½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        data = self._parse_html_table(html)
        if not data:
            return ""
        
        markdown_lines = []
        
        # è¡¨å¤´
        if data:
            header = data[0]
            markdown_lines.append("| " + " | ".join(header) + " |")
            markdown_lines.append("|" + "|".join(["---" for _ in header]) + "|")
            
            # è¡¨æ ¼å†…å®¹
            for row in data[1:]:
                # ç¡®ä¿è¡Œé•¿åº¦ä¸€è‡´
                padded_row = row + [''] * (len(header) - len(row))
                markdown_lines.append("| " + " | ".join(padded_row[:len(header)]) + " |")
        
        return '\n'.join(markdown_lines)
    
    def _basic_table_detection(self, image: np.ndarray, page_num: int) -> List[Dict]:
        """åŸºç¡€è¡¨æ ¼æ£€æµ‹ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        # è¿™é‡Œå¯ä»¥å®ç°åŸºäºOpenCVçš„è¡¨æ ¼çº¿æ£€æµ‹
        print("  ğŸ“‹ ä½¿ç”¨åŸºç¡€è¡¨æ ¼æ£€æµ‹...")
        return []


class MultiLanguageOCR:
    """å¤šè¯­è¨€OCRå¼•æ“ - æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ã€å¾·æ–‡ã€è¥¿ç­ç‰™è¯­ã€ç¹ä½“ç­‰"""
    
    # å…¨å±€å•ä¾‹
    _instance = None
    _ocr_engines = {}  # å¤šä¸ªè¯­è¨€å¼•æ“
    _initialized = False
    
    # è¯­è¨€æ˜ å°„
    LANGUAGE_MAP = {
        'ch': 'chinese_cht',    # ä¸­æ–‡(ç®€ç¹ä½“éƒ½æ”¯æŒ)
        'en': 'en',             # è‹±æ–‡
        'de': 'german',         # å¾·æ–‡
        'es': 'spanish',        # è¥¿ç­ç‰™è¯­
        'fr': 'french',         # æ³•æ–‡
        'ja': 'japan',          # æ—¥æ–‡
        'ko': 'korean',         # éŸ©æ–‡
        'ru': 'ru',             # ä¿„æ–‡
        'ar': 'arabic',         # é˜¿æ‹‰ä¼¯æ–‡
        'hi': 'hindi',          # å°åœ°è¯­
        'pt': 'portuguese',     # è‘¡è„ç‰™è¯­
        'it': 'italian',        # æ„å¤§åˆ©è¯­
        'auto': 'ch'            # è‡ªåŠ¨æ£€æµ‹é»˜è®¤ä½¿ç”¨ä¸­æ–‡å¼•æ“
    }
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not MultiLanguageOCR._initialized:
            self._init_engines()
            MultiLanguageOCR._initialized = True
    
    def _init_engines(self):
        """åˆå§‹åŒ–å¤šè¯­è¨€OCRå¼•æ“ - ä½¿ç”¨PaddleOCR 3.0 API"""
        from paddleocr import PaddleOCR
        import logging
        
        # ç¦ç”¨PaddleOCRçš„æ—¥å¿—è¾“å‡º
        logging.getLogger('ppocr').setLevel(logging.ERROR)
        
        # åˆå§‹åŒ–å¸¸ç”¨è¯­è¨€å¼•æ“
        print("ğŸŒ åˆå§‹åŒ–OCRå¼•æ“ï¼ˆPaddleOCR 3.0ï¼‰...")
        
        # PaddleOCR 3.0ç»Ÿä¸€ä½¿ç”¨ä¸€ä¸ªOCRå¼•æ“
        # æ–°ç‰ˆAPIå‚æ•°ä¸åŒï¼šuse_doc_orientation_classify, use_doc_unwarpingç­‰
        MultiLanguageOCR._ocr_engines['ch'] = PaddleOCR(
            use_doc_orientation_classify=False,
            use_doc_unwarping=False,
            use_textline_orientation=False
        )
        print("  âœ… PaddleOCRå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
        # PaddleOCR 3.0é»˜è®¤æ”¯æŒå¤šè¯­è¨€ï¼Œä¸éœ€è¦å•ç‹¬åˆå§‹åŒ–ä¸åŒè¯­è¨€å¼•æ“
        print(f"âœ… OCRå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def detect_language(self, image: np.ndarray, text_sample: str = None) -> str:
        """
        æ£€æµ‹å›¾ç‰‡æˆ–æ–‡æœ¬ä¸­çš„ä¸»è¦è¯­è¨€
        Args:
            image: è¾“å…¥å›¾åƒ
            text_sample: æ–‡æœ¬æ ·æœ¬ï¼ˆå¯é€‰ï¼‰
        Returns:
            è¯­è¨€ä»£ç 
        """
        if text_sample:
            # åŸºäºæ–‡æœ¬æ ·æœ¬æ£€æµ‹è¯­è¨€
            # ç®€å•çš„å¯å‘å¼è§„åˆ™
            if any('\u4e00' <= c <= '\u9fff' for c in text_sample):
                return 'ch'  # ä¸­æ–‡å­—ç¬¦
            elif any('\u3040' <= c <= '\u309f' or '\u30a0' <= c <= '\u30ff' for c in text_sample):
                return 'ja'  # æ—¥æ–‡
            elif any('\uac00' <= c <= '\ud7af' for c in text_sample):
                return 'ko'  # éŸ©æ–‡
            else:
                # æ£€æµ‹æ¬§æ´²è¯­è¨€ç‰¹å¾
                if any(c in 'Ã¤Ã¶Ã¼ÃŸÃ„Ã–Ãœ' for c in text_sample):
                    return 'de'  # å¾·æ–‡ç‰¹æ®Šå­—ç¬¦
                elif any(c in 'Ã¡Ã©Ã­Ã³ÃºÃ±ÃÃ‰ÃÃ“ÃšÃ‘Â¿Â¡' for c in text_sample):
                    return 'es'  # è¥¿ç­ç‰™è¯­ç‰¹æ®Šå­—ç¬¦
                else:
                    return 'en'  # é»˜è®¤è‹±æ–‡
        
        # å¦‚æœæ²¡æœ‰æ–‡æœ¬æ ·æœ¬ï¼Œé»˜è®¤ä½¿ç”¨ä¸­æ–‡å¼•æ“ï¼ˆæ”¯æŒèŒƒå›´æœ€å¹¿ï¼‰
        return 'ch'
    
    def ocr_with_language(self, image: np.ndarray, lang: str = 'auto') -> List[Dict]:
        """
        ä½¿ç”¨PaddleOCR 3.0è¿›è¡ŒOCRè¯†åˆ«
        Args:
            image: è¾“å…¥å›¾åƒ
            lang: è¯­è¨€ä»£ç ï¼ˆå¿½ç•¥ï¼Œ3.0ç‰ˆæœ¬è‡ªåŠ¨æ”¯æŒå¤šè¯­è¨€ï¼‰
        Returns:
            è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        # è·å–OCRå¼•æ“
        ocr_engine = MultiLanguageOCR._ocr_engines.get('ch')
        
        if ocr_engine is None:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„OCRå¼•æ“")
            return []
        
        try:
            # ä¿å­˜å›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆPaddleOCR 3.0çš„predictéœ€è¦æ–‡ä»¶è·¯å¾„ï¼‰
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                tmp_path = tmp_file.name
                cv2.imwrite(tmp_path, image)
            
            # ä½¿ç”¨predictæ–¹æ³•
            result = ocr_engine.predict(input=tmp_path)
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.unlink(tmp_path)
            
            # è§£æç»“æœ - PaddleOCR 3.0è¿”å›ç»“æœå¯¹è±¡
            text_results = []
            if result:
                for res in result:
                    # ç»“æœå¯¹è±¡å¯èƒ½æœ‰ä¸åŒçš„å±æ€§ï¼Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè§£æ
                    # æš‚æ—¶è¿”å›åŸå§‹ç»“æœ
                    text_results.append(res)
            
            return text_results
        except Exception as e:
            print(f"  âš ï¸  OCRè¯†åˆ«å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def ocr_multilang_auto(self, image: np.ndarray) -> Dict:
        """
        è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ€åˆé€‚çš„è¯­è¨€å¼•æ“
        Args:
            image: è¾“å…¥å›¾åƒ
        Returns:
            åŒ…å«è¯­è¨€ç±»å‹å’Œè¯†åˆ«ç»“æœçš„å­—å…¸
        """
        # å…ˆç”¨ä¸­æ–‡å¼•æ“å¿«é€Ÿè¯†åˆ«ä¸€æ¬¡
        quick_result = self.ocr_with_language(image, 'ch')
        
        if not quick_result:
            return {'language': 'unknown', 'result': []}
        
        # æå–æ ·æœ¬æ–‡æœ¬
        sample_text = ''.join([line[1][0] for line in quick_result[:5] if line])
        
        # æ£€æµ‹è¯­è¨€
        detected_lang = self.detect_language(image, sample_text)
        
        # å¦‚æœæ£€æµ‹åˆ°çš„è¯­è¨€ä¸æ˜¯ä¸­æ–‡ï¼Œé‡æ–°ç”¨å¯¹åº”è¯­è¨€å¼•æ“è¯†åˆ«
        if detected_lang != 'ch' and detected_lang in MultiLanguageOCR._ocr_engines:
            print(f"  ğŸ” æ£€æµ‹åˆ° {detected_lang} è¯­è¨€ï¼Œé‡æ–°è¯†åˆ«...")
            final_result = self.ocr_with_language(image, detected_lang)
            return {'language': detected_lang, 'result': final_result}
        
        return {'language': detected_lang, 'result': quick_result}


class FormulaExtractor:
    """æ•°å­¦å…¬å¼æå–å™¨ - è¯†åˆ«å›¾ç‰‡ä¸­çš„æ•°å­¦å…¬å¼"""
    
    # å…¨å±€å•ä¾‹
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if FormulaExtractor._initialized:
            return
        
        self.formula_engine = None
        self._init_formula_engine()
        FormulaExtractor._initialized = True
    
    def _init_formula_engine(self):
        """åˆå§‹åŒ–å…¬å¼è¯†åˆ«å¼•æ“"""
        try:
            # å°è¯•ä½¿ç”¨PaddleOCRè¯†åˆ«æ•°å­¦ç¬¦å·
            # æ³¨æ„ï¼šPaddleOCRé»˜è®¤ä¸æ”¯æŒLaTeXå…¬å¼è¯†åˆ«
            # è¿™é‡Œæä¾›ä¸€ä¸ªåŸºç¡€æ¡†æ¶ï¼Œå¯ä»¥åç»­é›†æˆä¸“é—¨çš„å…¬å¼è¯†åˆ«æ¨¡å‹
            print("âœ… å…¬å¼æå–å™¨åˆå§‹åŒ–å®Œæˆï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰")
        except Exception as e:
            print(f"âš ï¸  å…¬å¼è¯†åˆ«å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def detect_formula_regions(self, image: np.ndarray) -> List[Dict]:
        """
        æ£€æµ‹å›¾åƒä¸­å¯èƒ½åŒ…å«å…¬å¼çš„åŒºåŸŸ
        Args:
            image: è¾“å…¥å›¾åƒ
        Returns:
            å…¬å¼åŒºåŸŸåˆ—è¡¨
        """
        formula_regions = []
        
        # ç®€å•çš„å¯å‘å¼æ–¹æ³•ï¼šæ£€æµ‹åŒ…å«æ•°å­¦ç¬¦å·çš„åŒºåŸŸ
        # å¯ä»¥é€šè¿‡OCRè¯†åˆ«åæ£€æµ‹æ˜¯å¦åŒ…å«æ•°å­¦ç¬¦å·
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # ä½¿ç”¨å½¢æ€å­¦æ“ä½œæ‰¾åˆ°æ–‡æœ¬å—
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 5))
        dilated = cv2.dilate(binary, kernel, iterations=2)
        
        # æ‰¾åˆ°è½®å»“
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            
            # è¿‡æ»¤å¤ªå°çš„åŒºåŸŸ
            if w < 20 or h < 10:
                continue
            
            # æå–åŒºåŸŸ
            roi = image[y:y+h, x:x+w]
            
            formula_regions.append({
                'bbox': [x, y, x+w, y+h],
                'image': roi
            })
        
        return formula_regions
    
    def extract_formulas(self, image: np.ndarray) -> List[Dict]:
        """
        æå–å›¾ç‰‡ä¸­çš„æ•°å­¦å…¬å¼
        Args:
            image: è¾“å…¥å›¾åƒ
        Returns:
            å…¬å¼åˆ—è¡¨ï¼ŒåŒ…å«ä½ç½®å’Œè¯†åˆ«ç»“æœ
        """
        formulas = []
        
        try:
            # æ£€æµ‹å…¬å¼åŒºåŸŸ
            regions = self.detect_formula_regions(image)
            
            if not regions:
                return formulas
            
            print(f"  ğŸ”¢ æ£€æµ‹åˆ° {len(regions)} ä¸ªå¯èƒ½çš„å…¬å¼åŒºåŸŸ")
            
            # å¯¹æ¯ä¸ªåŒºåŸŸè¿›è¡ŒOCRè¯†åˆ«
            from paddleocr import PaddleOCR
            import logging
            logging.getLogger('ppocr').setLevel(logging.ERROR)
            
            # ä½¿ç”¨PaddleOCR 3.0 API
            ocr_engine = PaddleOCR(
                use_doc_orientation_classify=False,
                use_doc_unwarping=False,
                use_textline_orientation=False
            )
            
            for idx, region in enumerate(regions):
                roi = region['image']
                bbox = region['bbox']
                
                # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ï¼ˆPaddleOCR 3.0éœ€è¦æ–‡ä»¶è·¯å¾„ï¼‰
                import tempfile
                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                    tmp_path = tmp_file.name
                    cv2.imwrite(tmp_path, roi)
                
                # ä½¿ç”¨predictæ–¹æ³•
                result = ocr_engine.predict(input=tmp_path)
                
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                os.unlink(tmp_path)
                
                if result:
                    # æå–æ–‡æœ¬
                    text_parts = []
                    for res in result:
                        if hasattr(res, 'text'):
                            text_parts.append(res.text)
                        else:
                            text_parts.append(str(res))
                    text = ' '.join(text_parts)
                    
                    # æ£€æµ‹æ˜¯å¦åŒ…å«æ•°å­¦ç¬¦å·
                    math_symbols = set('+-*/=()[]{}^_âˆ«âˆ‘âˆâˆšâˆ‚âˆ‡â‰ˆâ‰ â‰¤â‰¥âˆ')
                    if any(c in math_symbols for c in text):
                        formulas.append({
                            'bbox': bbox,
                            'text': text,
                            'confidence': 'medium',
                            'type': 'inline_math'
                        })
            
            print(f"  âœ… æå–åˆ° {len(formulas)} ä¸ªå…¬å¼")
            
        except Exception as e:
            print(f"  âš ï¸  å…¬å¼æå–å¤±è´¥: {e}")
        
        return formulas


class TableOfContentsExtractor:
    """ç›®å½•æå–å™¨ - è¯†åˆ«å¹¶åˆ©ç”¨æ–‡æ¡£ç›®å½•"""
    
    def __init__(self):
        self.toc_patterns = [
            r'^\s*ç›®\s*å½•\s*$',
            r'^\s*CONTENTS?\s*$',
            r'^\s*TABLE\s+OF\s+CONTENTS\s*$',
            r'^\s*ç´¢\s*å¼•\s*$',
        ]
    
    def extract_toc_from_pdf(self, pdf_path: str) -> List[Dict]:
        """
        ä»PDFä¸­æå–ç›®å½•ä¿¡æ¯
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
        Returns:
            ç›®å½•é¡¹åˆ—è¡¨
        """
        import fitz
        toc_items = []
        
        try:
            doc = fitz.open(pdf_path)
            
            # æ–¹æ³•1ï¼šå°è¯•ä»PDFå…ƒæ•°æ®ä¸­è·å–ç›®å½•
            toc = doc.get_toc()
            
            if toc:
                print(f"  ğŸ“‘ ä»PDFå…ƒæ•°æ®æå–åˆ° {len(toc)} ä¸ªç›®å½•é¡¹")
                for item in toc:
                    level, title, page = item
                    toc_items.append({
                        'level': level,
                        'title': title,
                        'page': page,
                        'source': 'metadata'
                    })
            else:
                # æ–¹æ³•2ï¼šé€šè¿‡OCRè¯†åˆ«ç›®å½•é¡µ
                print("  ğŸ“‘ PDFå…ƒæ•°æ®ä¸­æ— ç›®å½•ï¼Œå°è¯•OCRè¯†åˆ«...")
                toc_items = self._extract_toc_by_ocr(doc)
            
            doc.close()
            
        except Exception as e:
            print(f"  âš ï¸  ç›®å½•æå–å¤±è´¥: {e}")
        
        return toc_items
    
    def _extract_toc_by_ocr(self, doc) -> List[Dict]:
        """é€šè¿‡OCRè¯†åˆ«ç›®å½•é¡µ"""
        import re
        import fitz  # PyMuPDF
        from paddleocr import PaddleOCR
        import logging
        
        # ç¦ç”¨æ—¥å¿—
        logging.getLogger('ppocr').setLevel(logging.ERROR)
        
        toc_items = []
        # ä½¿ç”¨PaddleOCR 3.0 API
        ocr_engine = PaddleOCR(
            use_doc_orientation_classify=False,
            use_doc_unwarping=False,
            use_textline_orientation=False
        )
        
        # é€šå¸¸ç›®å½•åœ¨å‰å‡ é¡µ
        max_pages = min(10, len(doc))
        
        for page_num in range(max_pages):
            page = doc[page_num]
            
            # è½¬æ¢ä¸ºå›¾åƒ
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            img_data = pix.tobytes("png")
            
            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ï¼ˆPaddleOCR 3.0éœ€è¦æ–‡ä»¶è·¯å¾„ï¼‰
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                tmp_path = tmp_file.name
                tmp_file.write(img_data)
            
            # ä½¿ç”¨predictæ–¹æ³•
            result = ocr_engine.predict(input=tmp_path)
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.unlink(tmp_path)
            
            if not result:
                continue
            
            # æå–æ–‡æœ¬ - PaddleOCR 3.0è¿”å›ç»“æœå¯¹è±¡
            text_lines = []
            for res in result:
                # éœ€è¦æ ¹æ®å®é™…è¿”å›çš„æ•°æ®ç»“æ„æå–æ–‡æœ¬
                # æš‚æ—¶å°è¯•è·å–textå±æ€§æˆ–è½¬å­—ç¬¦ä¸²
                if hasattr(res, 'text'):
                    text_lines.append(res.text)
                else:
                    text_lines.append(str(res))
            full_text = '\n'.join(text_lines)
            
            # æ£€æµ‹æ˜¯å¦æ˜¯ç›®å½•é¡µ
            is_toc_page = any(re.search(pattern, full_text, re.IGNORECASE | re.MULTILINE) 
                            for pattern in self.toc_patterns)
            
            if is_toc_page:
                print(f"  ğŸ“– å‘ç°ç›®å½•é¡µï¼šç¬¬ {page_num + 1} é¡µ")
                
                # è§£æç›®å½•é¡¹ï¼ˆç®€å•çš„æ¨¡å¼åŒ¹é…ï¼‰
                # æ ¼å¼: "ç« èŠ‚æ ‡é¢˜ .... é¡µç "
                toc_pattern = r'^(.+?)\s*[\.ã€‚â€¦]+\s*(\d+)\s*$'
                
                for line in text_lines:
                    match = re.match(toc_pattern, line.strip())
                    if match:
                        title = match.group(1).strip()
                        page = int(match.group(2))
                        
                        # åˆ¤æ–­å±‚çº§ï¼ˆåŸºäºç¼©è¿›æˆ–æ•°å­—ï¼‰
                        level = 1
                        if re.match(r'^\s{2,}', line):
                            level = 2
                        elif re.match(r'^\s{4,}', line):
                            level = 3
                        
                        toc_items.append({
                            'level': level,
                            'title': title,
                            'page': page,
                            'source': 'ocr'
                        })
                
                break  # æ‰¾åˆ°ç›®å½•é¡µååœæ­¢
        
        if toc_items:
            print(f"  âœ… OCRè¯†åˆ«åˆ° {len(toc_items)} ä¸ªç›®å½•é¡¹")
        
        return toc_items
    
    def generate_toc_structure(self, toc_items: List[Dict]) -> str:
        """
        ç”Ÿæˆæ ¼å¼åŒ–çš„ç›®å½•ç»“æ„
        Args:
            toc_items: ç›®å½•é¡¹åˆ—è¡¨
        Returns:
            æ ¼å¼åŒ–çš„ç›®å½•æ–‡æœ¬
        """
        if not toc_items:
            return ""
        
        lines = ["# æ–‡æ¡£ç›®å½•\n"]
        
        for item in toc_items:
            indent = "  " * (item['level'] - 1)
            title = item['title']
            page = item['page']
            lines.append(f"{indent}- {title} (ç¬¬{page}é¡µ)")
        
        return '\n'.join(lines)


class ComprehensiveOCRSystem:
    """ç»¼åˆOCRç³»ç»Ÿ - é›†æˆæ‰€æœ‰åŠŸèƒ½"""
    
    # å…¨å±€å•ä¾‹å®ä¾‹
    _instance = None
    _initialized = False
    
    def __new__(cls):
        """å•ä¾‹æ¨¡å¼ï¼šç¡®ä¿æ•´ä¸ªç¨‹åºåªæœ‰ä¸€ä¸ªOCRç³»ç»Ÿå®ä¾‹"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–ç»¼åˆOCRç³»ç»Ÿï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰"""
        # é¿å…é‡å¤åˆå§‹åŒ–
        if ComprehensiveOCRSystem._initialized:
            return
        
        print("ğŸš€ åˆå§‹åŒ–ç»¼åˆOCRç³»ç»Ÿï¼ˆå…¨å±€å•ä¾‹ï¼‰...")
        self.preprocessor = ImagePreprocessor()
        self.table_extractor = AdvancedTableExtractor()
        self.multilang_ocr = MultiLanguageOCR()
        self.formula_extractor = FormulaExtractor()
        self.toc_extractor = TableOfContentsExtractor()
        
        ComprehensiveOCRSystem._initialized = True
        print("âœ… OCRç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œåç»­æ–‡ä»¶å°†å¤ç”¨æ­¤å®ä¾‹")
    
    def process_document(self, file_path: str, 
                        auto_rotate: bool = True,
                        remove_watermark: bool = False,
                        enhance_blur: bool = True,
                        extract_tables: bool = True,
                        extract_formulas: bool = False,
                        extract_toc: bool = True,
                        language: str = 'auto') -> Dict:
        """
        å…¨é¢å¤„ç†æ–‡æ¡£
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            auto_rotate: æ˜¯å¦è‡ªåŠ¨æ—‹è½¬
            remove_watermark: æ˜¯å¦å»é™¤æ°´å°
            enhance_blur: æ˜¯å¦å¢å¼ºæ¨¡ç³Šå›¾åƒ
            extract_tables: æ˜¯å¦æå–è¡¨æ ¼
            extract_formulas: æ˜¯å¦æå–å…¬å¼
            extract_toc: æ˜¯å¦æå–ç›®å½•
            language: è¯­è¨€è®¾ç½®
        Returns:
            å¤„ç†ç»“æœ
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¤„ç†æ–‡æ¡£: {os.path.basename(file_path)}")
        print(f"{'='*60}\n")
        
        import fitz  # PyMuPDF
        
        doc = fitz.open(file_path)
        results = {
            'file_name': os.path.basename(file_path),
            'total_pages': len(doc),
            'toc': [],
            'pages': []
        }
        
        # 1. æå–ç›®å½•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if extract_toc:
            print("\nğŸ“‘ æå–æ–‡æ¡£ç›®å½•...")
            toc_items = self.toc_extractor.extract_toc_from_pdf(file_path)
            results['toc'] = toc_items
            if toc_items:
                toc_text = self.toc_extractor.generate_toc_structure(toc_items)
                print(f"\n{toc_text}\n")
        
        for page_num in range(len(doc)):
            print(f"\nå¤„ç†ç¬¬ {page_num + 1}/{len(doc)} é¡µ...")
            
            page = doc[page_num]
            
            # è½¬æ¢ä¸ºå›¾åƒ
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            img_data = pix.tobytes("png")
            image = Image.open(io.BytesIO(img_data))
            img_array = np.array(image)
            
            # è½¬æ¢é¢œè‰²ç©ºé—´ï¼ˆPILæ˜¯RGBï¼ŒOpenCVæ˜¯BGRï¼‰
            if len(img_array.shape) == 3:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            
            page_result = {
                'page_number': page_num + 1,
                'text': '',
                'tables': [],
                'formulas': [],
                'processing_steps': []
            }
            
            # 1. å›¾åƒé¢„å¤„ç†
            processed_image = img_array.copy()
            
            # æ£€æµ‹æ¨¡ç³Šåº¦
            blur_score = self.preprocessor.detect_blur(processed_image)
            if blur_score < 100 and enhance_blur:
                page_result['processing_steps'].append('æ¨¡ç³Šå¢å¼º')
                processed_image = self.preprocessor.enhance_blurry_image(processed_image)
            
            # è‡ªåŠ¨æ—‹è½¬
            if auto_rotate:
                page_result['processing_steps'].append('æ–¹å‘æ£€æµ‹ä¸æ—‹è½¬')
                processed_image = self.preprocessor.detect_and_rotate(processed_image)
            
            # å»æ°´å°
            if remove_watermark:
                page_result['processing_steps'].append('æ°´å°å»é™¤')
                processed_image = self.preprocessor.remove_watermark(processed_image, method='auto')
            
            # 2. è¡¨æ ¼æå–
            if extract_tables:
                tables = self.table_extractor.extract_table_with_merged_cells(
                    processed_image, 
                    page_num
                )
                page_result['tables'] = tables
            
            # 3. æ–‡æœ¬OCRï¼ˆä½¿ç”¨å¤šè¯­è¨€è‡ªåŠ¨æ£€æµ‹ï¼‰
            if language == 'auto':
                # è‡ªåŠ¨æ£€æµ‹è¯­è¨€å¹¶ä½¿ç”¨æœ€åˆé€‚çš„å¼•æ“
                ocr_output = self.multilang_ocr.ocr_multilang_auto(processed_image)
                detected_lang = ocr_output['language']
                ocr_results = ocr_output['result']
                page_result['detected_language'] = detected_lang
                print(f"  ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {detected_lang}")
            else:
                # ä½¿ç”¨æŒ‡å®šè¯­è¨€å¼•æ“
                ocr_results = self.multilang_ocr.ocr_with_language(processed_image, language)
                page_result['detected_language'] = language
            
            text_lines = []
            if ocr_results:
                # PaddleOCR 3.0è¿”å›ç»“æœå¯¹è±¡ï¼Œéœ€è¦æå–æ–‡æœ¬
                for res in ocr_results:
                    if hasattr(res, 'text'):
                        text_lines.append(res.text)
                    elif hasattr(res, '__dict__'):
                        # å°è¯•ä»å¯¹è±¡å±æ€§ä¸­æå–
                        text_lines.append(str(res))
                    else:
                        # æ—§æ ¼å¼å…¼å®¹
                        if isinstance(res, (list, tuple)) and len(res) >= 2:
                            text = res[1][0] if isinstance(res[1], (list, tuple)) else res[1]
                            text_lines.append(str(text))
            
            page_result['text'] = '\n'.join(text_lines)
            
            # 4. å…¬å¼æå–ï¼ˆå¯é€‰ï¼‰
            if extract_formulas:
                formulas = self.formula_extractor.extract_formulas(processed_image)
                page_result['formulas'] = formulas
            
            results['pages'].append(page_result)
            
            print(f"  âœ… å®Œæˆ - æå–æ–‡æœ¬: {len(text_lines)}è¡Œ, è¡¨æ ¼: {len(page_result['tables'])}ä¸ª")
        
        doc.close()
        
        print(f"\n{'='*60}")
        print(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼")
        print(f"{'='*60}\n")
        
        return results
    
    def export_results(self, results: Dict, output_path: str = None):
        """
        å¯¼å‡ºå¤„ç†ç»“æœ
        Args:
            results: å¤„ç†ç»“æœ
            output_path: è¾“å‡ºè·¯å¾„
        """
        if output_path is None:
            output_path = f"{results['file_name']}_ocr_results.json"
        
        import json
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        # åŒæ—¶ç”Ÿæˆå¯è¯»çš„æ–‡æœ¬ç‰ˆæœ¬
        text_output = output_path.replace('.json', '.txt')
        with open(text_output, 'w', encoding='utf-8') as f:
            f.write(f"æ–‡æ¡£: {results['file_name']}\n")
            f.write(f"æ€»é¡µæ•°: {results['total_pages']}\n")
            f.write("="*60 + "\n\n")
            
            # è¾“å‡ºç›®å½•ï¼ˆå¦‚æœæœ‰ï¼‰
            if results.get('toc'):
                f.write("\n## æ–‡æ¡£ç›®å½•\n\n")
                for item in results['toc']:
                    indent = "  " * (item['level'] - 1)
                    f.write(f"{indent}- {item['title']} (ç¬¬{item['page']}é¡µ)\n")
                f.write("\n" + "="*60 + "\n\n")
            
            for page in results['pages']:
                f.write(f"\nç¬¬ {page['page_number']} é¡µ")
                if page.get('detected_language'):
                    f.write(f" [è¯­è¨€: {page['detected_language']}]")
                f.write("\n")
                f.write("-"*60 + "\n")
                
                if page['processing_steps']:
                    f.write(f"å¤„ç†æ­¥éª¤: {', '.join(page['processing_steps'])}\n\n")
                
                if page['tables']:
                    f.write(f"[æ£€æµ‹åˆ° {len(page['tables'])} ä¸ªè¡¨æ ¼]\n\n")
                    for table in page['tables']:
                        f.write(table.get('markdown', '') + '\n\n')
                
                if page.get('formulas'):
                    f.write(f"[æ£€æµ‹åˆ° {len(page['formulas'])} ä¸ªå…¬å¼]\n")
                    for formula in page['formulas']:
                        f.write(f"  - {formula['text']}\n")
                    f.write("\n")
                
                f.write(page['text'] + '\n\n')
        
        print(f"âœ… æ–‡æœ¬ç‰ˆæœ¬å·²ä¿å­˜åˆ°: {text_output}")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("=== é«˜çº§OCRç³»ç»Ÿ - PaddleOCRå®Œæ•´ç‰ˆ ===\n")
    
    print("âœ¨ ç³»ç»ŸåŠŸèƒ½æ¸…å•:")
    print("\nğŸ“„ æ–‡æ¡£å¤„ç†:")
    print("  âœ… è‡ªåŠ¨æ—‹è½¬çº æ­£ï¼ˆæ£€æµ‹å€¾æ–œå¹¶æ ¡æ­£ï¼‰")
    print("  âœ… æ°´å°å»é™¤ï¼ˆè‡ªåŠ¨æ£€æµ‹å¹¶å»é™¤æ°´å°ï¼‰")
    print("  âœ… æ¨¡ç³Šå›¾åƒå¢å¼ºï¼ˆé”åŒ–+å»å™ª+å¯¹æ¯”åº¦å¢å¼ºï¼‰")
    
    print("\nğŸ“Š è¡¨æ ¼è¯†åˆ«:")
    print("  âœ… å¤æ‚è¡¨æ ¼è¯†åˆ«ï¼ˆä½¿ç”¨PP-Structureï¼‰")
    print("  âœ… æ”¯æŒåˆå¹¶å•å…ƒæ ¼")
    print("  âœ… è¾“å‡ºHTMLå’ŒMarkdownæ ¼å¼")
    print("  âœ… å¼‚å½¢è¡¨æ ¼å¤„ç†")
    
    print("\nğŸŒ å¤šè¯­è¨€æ”¯æŒ:")
    print("  âœ… ä¸­æ–‡ï¼ˆç®€ä½“+ç¹ä½“ï¼‰")
    print("  âœ… è‹±æ–‡")
    print("  âœ… å¾·æ–‡")
    print("  âœ… è¥¿ç­ç‰™è¯­")
    print("  âœ… è‡ªåŠ¨è¯­è¨€æ£€æµ‹")
    
    print("\nğŸ”¢ ç‰¹æ®Šå†…å®¹:")
    print("  âœ… æ•°å­¦å…¬å¼è¯†åˆ«")
    print("  âœ… å›¾ç‰‡ä¸­æ–‡å­—æå–")
    print("  âœ… æ¨¡ç³Šæ‰«æä»¶å¤„ç†")
    
    print("\nğŸ“‘ æ–‡æ¡£ç»“æ„:")
    print("  âœ… ç›®å½•è¯†åˆ«å’Œæå–")
    print("  âœ… ä»PDFå…ƒæ•°æ®æå–ç›®å½•")
    print("  âœ… OCRè¯†åˆ«ç›®å½•é¡µ")
    
    print("\n" + "="*60)
    print("ä½¿ç”¨ç¤ºä¾‹:")
    print("="*60)
    print("""
from advanced_ocr_system import ComprehensiveOCRSystem

# åˆ›å»ºç³»ç»Ÿï¼ˆå…¨å±€å•ä¾‹ï¼Œå¤šä¸ªæ–‡æ¡£å…±äº«ï¼‰
ocr_system = ComprehensiveOCRSystem()

# å¤„ç†æ–‡æ¡£
results = ocr_system.process_document(
    'document.pdf',
    auto_rotate=True,         # è‡ªåŠ¨æ—‹è½¬çº æ­£
    remove_watermark=True,    # å»é™¤æ°´å°
    enhance_blur=True,        # å¢å¼ºæ¨¡ç³Šå›¾åƒ
    extract_tables=True,      # æå–è¡¨æ ¼ï¼ˆPP-Structureï¼‰
    extract_formulas=True,    # æå–æ•°å­¦å…¬å¼
    extract_toc=True,         # æå–ç›®å½•
    language='auto'           # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
)

# å¯¼å‡ºç»“æœï¼ˆJSON + å¯è¯»æ–‡æœ¬ï¼‰
ocr_system.export_results(results, 'output.json')

# è®¿é—®ç»“æœ
print(f"æ–‡æ¡£æ€»é¡µæ•°: {results['total_pages']}")
print(f"ç›®å½•é¡¹æ•°: {len(results['toc'])}")
for page in results['pages']:
    print(f"ç¬¬{page['page_number']}é¡µ:")
    print(f"  è¯­è¨€: {page.get('detected_language', 'unknown')}")
    print(f"  è¡¨æ ¼æ•°: {len(page['tables'])}")
    print(f"  å…¬å¼æ•°: {len(page.get('formulas', []))}")
    print(f"  æ–‡æœ¬è¡Œæ•°: {len(page['text'].split(chr(10)))}")
""")
    
    print("\n" + "="*60)
    print("æ”¯æŒçš„æ–‡ä»¶ç±»å‹:")
    print("="*60)
    print("  ğŸ“„ PDFæ–‡æ¡£")
    print("  ğŸ“„ æ‰«æä»¶ï¼ˆè‡ªåŠ¨å¢å¼ºï¼‰")
    print("  ğŸ“„ å¸¦æ°´å°æ–‡æ¡£ï¼ˆè‡ªåŠ¨å»é™¤ï¼‰")
    print("  ğŸ“„ å€¾æ–œæ–‡æ¡£ï¼ˆè‡ªåŠ¨çº æ­£ï¼‰")
    print("  ğŸ“„ å¤šè¯­è¨€æ··åˆæ–‡æ¡£ï¼ˆè‡ªåŠ¨è¯†åˆ«ï¼‰")
    print("  ğŸ“„ åŒ…å«å¤æ‚è¡¨æ ¼çš„æ–‡æ¡£")
    print("  ğŸ“„ åŒ…å«æ•°å­¦å…¬å¼çš„æ–‡æ¡£")

