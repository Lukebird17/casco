#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
@File    :   advanced_ocr_system.py
@Time    :   2025/11/16
@Desc    :   é«˜çº§OCRç³»ç»Ÿ - æ”¯æŒè¡¨æ ¼ã€å¤šè¯­è¨€ã€æ°´å°å¤„ç†ã€å…¬å¼è¯†åˆ«ç­‰
'''

import os
import cv2
import numpy as np
from typing import Dict, List, Tuple, Optional
from PIL import Image
import io


class ImagePreprocessor:
    """å›¾åƒé¢„å¤„ç†å™¨ - å¤„ç†æ—‹è½¬ã€æ°´å°ã€æ¨¡ç³Šç­‰é—®é¢˜"""
    
    @staticmethod
    def detect_and_rotate(image: np.ndarray) -> np.ndarray:
        """
        æ£€æµ‹å›¾ç‰‡æ–¹å‘å¹¶è‡ªåŠ¨æ—‹è½¬
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆnumpyæ•°ç»„ï¼‰
        Returns:
            æ—‹è½¬åçš„å›¾åƒ
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # æ£€æµ‹æ–‡æœ¬æ–¹å‘ï¼ˆä½¿ç”¨è¾¹ç¼˜æ£€æµ‹ï¼‰
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)
        
        if lines is not None:
            angles = []
            for line in lines:
                x1, y1, x2, y2 = line[0]
                angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
                angles.append(angle)
            
            # è®¡ç®—å¹³å‡è§’åº¦
            median_angle = np.median(angles)
            
            # å¦‚æœè§’åº¦æ˜æ˜¾åç¦»ï¼Œè¿›è¡Œæ—‹è½¬
            if abs(median_angle) > 5:
                print(f"  ğŸ”„ æ£€æµ‹åˆ°å›¾ç‰‡å€¾æ–œ {median_angle:.1f}Â°ï¼Œæ­£åœ¨æ—‹è½¬...")
                height, width = image.shape[:2]
                center = (width // 2, height // 2)
                rotation_matrix = cv2.getRotationMatrix2D(center, -median_angle, 1.0)
                image = cv2.warpAffine(image, rotation_matrix, (width, height), 
                                      flags=cv2.INTER_CUBIC, 
                                      borderMode=cv2.BORDER_REPLICATE)
        
        return image
    
    @staticmethod
    def remove_watermark(image: np.ndarray, method: str = 'auto') -> np.ndarray:
        """
        å»é™¤æ°´å°
        Args:
            image: è¾“å…¥å›¾åƒ
            method: å»é™¤æ–¹æ³•ï¼ˆ'auto', 'threshold', 'inpaint'ï¼‰
        Returns:
            å»æ°´å°åçš„å›¾åƒ
        """
        print("  ğŸ¨ æ­£åœ¨å»é™¤æ°´å°...")
        
        if method == 'threshold':
            # æ–¹æ³•1ï¼šé˜ˆå€¼æ³•ï¼ˆé€‚ç”¨äºæµ…è‰²æ°´å°ï¼‰
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
            _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
            
            # æ‰¾åˆ°æ°´å°åŒºåŸŸ
            kernel = np.ones((5, 5), np.uint8)
            mask = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
            mask = cv2.bitwise_not(mask)
            
            # ä¿®å¤æ°´å°åŒºåŸŸ
            result = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)
            return result
            
        elif method == 'auto':
            # æ–¹æ³•2ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶å»é™¤ï¼ˆç®€å•çš„å¯¹æ¯”åº¦å¢å¼ºï¼‰
            # å¯¹äºè½»å¾®æ°´å°ï¼Œå¢å¼ºå¯¹æ¯”åº¦å¯ä»¥æ”¹å–„è¯†åˆ«
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB) if len(image.shape) == 3 else cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHEï¼ˆå¯¹æ¯”åº¦é™åˆ¶è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡ï¼‰
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            
            enhanced = cv2.merge([l, a, b])
            result = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
            return result
        
        return image
    
    @staticmethod
    def enhance_blurry_image(image: np.ndarray) -> np.ndarray:
        """
        å¢å¼ºæ¨¡ç³Šå›¾åƒ
        Args:
            image: è¾“å…¥å›¾åƒ
        Returns:
            å¢å¼ºåçš„å›¾åƒ
        """
        print("  âœ¨ å¢å¼ºæ¨¡ç³Šå›¾åƒ...")
        
        # 1. é”åŒ–
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]])
        sharpened = cv2.filter2D(image, -1, kernel)
        
        # 2. å»å™ª
        denoised = cv2.fastNlMeansDenoisingColored(sharpened, None, 10, 10, 7, 21) if len(image.shape) == 3 else cv2.fastNlMeansDenoising(sharpened, None, 10, 7, 21)
        
        # 3. å¯¹æ¯”åº¦å¢å¼º
        lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB) if len(image.shape) == 3 else cv2.cvtColor(cv2.cvtColor(denoised, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        enhanced = cv2.merge([l, a, b])
        result = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
        
        return result
    
    @staticmethod
    def detect_blur(image: np.ndarray) -> float:
        """
        æ£€æµ‹å›¾åƒæ¨¡ç³Šåº¦
        Args:
            image: è¾“å…¥å›¾åƒ
        Returns:
            æ¨¡ç³Šåº¦åˆ†æ•°ï¼ˆè¶Šä½è¶Šæ¨¡ç³Šï¼‰
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        return laplacian_var


class AdvancedTableExtractor:
    """é«˜çº§è¡¨æ ¼æå–å™¨ - æ”¯æŒåˆå¹¶å•å…ƒæ ¼çš„å¤æ‚è¡¨æ ¼"""
    
    def __init__(self):
        self.table_engine = None
        self._init_table_engine()
    
    def _init_table_engine(self):
        """åˆå§‹åŒ–è¡¨æ ¼è¯†åˆ«å¼•æ“"""
        from paddleocr import PPStructure
        self.table_engine = PPStructure(
            show_log=False,
            use_gpu=False,
            layout=False,  # ä¸ä½¿ç”¨ç‰ˆé¢åˆ†æï¼Œåªåšè¡¨æ ¼è¯†åˆ«
            table=True,     # å¯ç”¨è¡¨æ ¼è¯†åˆ«
            ocr=True        # å¯ç”¨OCR
        )
        print("âœ… PaddleOCRè¡¨æ ¼è¯†åˆ«å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    
    def extract_table_with_merged_cells(self, image: np.ndarray, page_num: int = 0) -> List[Dict]:
        """
        æå–åŒ…å«åˆå¹¶å•å…ƒæ ¼çš„å¤æ‚è¡¨æ ¼
        Args:
            image: å›¾åƒæ•°ç»„
            page_num: é¡µç 
        Returns:
            è¡¨æ ¼åˆ—è¡¨
        """
        tables = []
        
        print(f"  ğŸ“Š ä½¿ç”¨PaddleOCRè¯†åˆ«å¤æ‚è¡¨æ ¼...")
        result = self.table_engine(image)
        
        for i, item in enumerate(result):
            if item['type'] == 'table':
                # æå–è¡¨æ ¼HTML
                table_html = item.get('res', {}).get('html', '')
                
                # è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®
                table_data = self._parse_html_table(table_html)
                
                tables.append({
                    'page': page_num,
                    'table_index': i + 1,
                    'html': table_html,
                    'data': table_data,
                    'has_merged_cells': self._detect_merged_cells(table_html),
                    'markdown': self._html_to_markdown(table_html)
                })
        
        print(f"  âœ… è¯†åˆ«åˆ° {len(tables)} ä¸ªè¡¨æ ¼")
        
        return tables
    
    def _detect_merged_cells(self, html: str) -> bool:
        """æ£€æµ‹æ˜¯å¦åŒ…å«åˆå¹¶å•å…ƒæ ¼"""
        return 'colspan' in html or 'rowspan' in html
    
    def _parse_html_table(self, html: str) -> List[List[str]]:
        """è§£æHTMLè¡¨æ ¼ä¸ºäºŒç»´æ•°ç»„"""
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html, 'html.parser')
        table = soup.find('table')
        
        if not table:
            return []
        
        data = []
        for row in table.find_all('tr'):
            row_data = []
            for cell in row.find_all(['td', 'th']):
                text = cell.get_text(strip=True)
                colspan = int(cell.get('colspan', 1))
                
                # å¤„ç†åˆå¹¶å•å…ƒæ ¼
                row_data.append(text)
                for _ in range(colspan - 1):
                    row_data.append('')
            
            data.append(row_data)
        
        return data
    
    def _html_to_markdown(self, html: str) -> str:
        """å°†HTMLè¡¨æ ¼è½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        data = self._parse_html_table(html)
        if not data:
            return ""
        
        markdown_lines = []
        
        # è¡¨å¤´
        if data:
            header = data[0]
            markdown_lines.append("| " + " | ".join(header) + " |")
            markdown_lines.append("|" + "|".join(["---" for _ in header]) + "|")
            
            # è¡¨æ ¼å†…å®¹
            for row in data[1:]:
                # ç¡®ä¿è¡Œé•¿åº¦ä¸€è‡´
                padded_row = row + [''] * (len(header) - len(row))
                markdown_lines.append("| " + " | ".join(padded_row[:len(header)]) + " |")
        
        return '\n'.join(markdown_lines)
    
    def _basic_table_detection(self, image: np.ndarray, page_num: int) -> List[Dict]:
        """åŸºç¡€è¡¨æ ¼æ£€æµ‹ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        # è¿™é‡Œå¯ä»¥å®ç°åŸºäºOpenCVçš„è¡¨æ ¼çº¿æ£€æµ‹
        print("  ğŸ“‹ ä½¿ç”¨åŸºç¡€è¡¨æ ¼æ£€æµ‹...")
        return []


class MultiLanguageOCR:
    """å¤šè¯­è¨€OCRå¼•æ“"""
    
    # ç±»çº§åˆ«çš„å•ä¾‹å¼•æ“
    _ocr_engine = None
    _initialized = False
    
    def __init__(self):
        if not MultiLanguageOCR._initialized:
            self._init_engine()
            MultiLanguageOCR._initialized = True
        self.ocr_engine = MultiLanguageOCR._ocr_engine
    
    def _init_engine(self):
        """åˆå§‹åŒ–OCRå¼•æ“ï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰"""
        from paddleocr import PaddleOCR
        
        # åªåˆå§‹åŒ–ä¸€ä¸ªé€šç”¨å¼•æ“ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
        MultiLanguageOCR._ocr_engine = PaddleOCR(
            use_angle_cls=True,
            lang='ch',  # ä¸­æ–‡æ¨¡å‹åŒæ—¶æ”¯æŒç®€ç¹ä½“å’Œè‹±æ–‡
            use_gpu=False,
            show_log=False
        )
        
        print("âœ… PaddleOCRå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        print(f"   æ”¯æŒè¯­è¨€: ä¸­æ–‡(ç®€ç¹ä½“)ã€è‹±æ–‡ç­‰")
    
    def detect_language(self, image: np.ndarray) -> str:
        """æ£€æµ‹å›¾ç‰‡ä¸­çš„ä¸»è¦è¯­è¨€ï¼ˆç®€åŒ–ç‰ˆï¼Œç›´æ¥è¿”å›é€šç”¨ï¼‰"""
        return 'chinese'  # ä½¿ç”¨ä¸­æ–‡å¼•æ“ï¼ˆåŒæ—¶æ”¯æŒè‹±æ–‡ï¼‰
    
    def ocr_with_language(self, image: np.ndarray, lang: str = 'auto') -> List[Dict]:
        """
        ä½¿ç”¨OCRè¯†åˆ«å›¾åƒ
        Args:
            image: è¾“å…¥å›¾åƒ
            lang: è¯­è¨€ä»£ç ï¼ˆå¿½ç•¥ï¼Œä½¿ç”¨é€šç”¨å¼•æ“ï¼‰
        Returns:
            è¯†åˆ«ç»“æœ
        """
        result = self.ocr_engine.ocr(image, cls=True)
        return result[0] if result and result[0] else []


class FormulaExtractor:
    """æ•°å­¦å…¬å¼æå–å™¨ï¼ˆå ä½ï¼Œæš‚ä¸å¯ç”¨ï¼‰"""
    
    def __init__(self):
        self.formula_engine = None
    
    def extract_formulas(self, image: np.ndarray) -> List[Dict]:
        """æå–å…¬å¼ï¼ˆæš‚ä¸å¯ç”¨ï¼‰"""
        return []


class ComprehensiveOCRSystem:
    """ç»¼åˆOCRç³»ç»Ÿ - é›†æˆæ‰€æœ‰åŠŸèƒ½"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç»¼åˆOCRç³»ç»Ÿ"""
        self.preprocessor = ImagePreprocessor()
        self.table_extractor = AdvancedTableExtractor()
        self.multilang_ocr = MultiLanguageOCR()
        self.formula_extractor = FormulaExtractor()
    
    def process_document(self, file_path: str, 
                        auto_rotate: bool = True,
                        remove_watermark: bool = False,
                        enhance_blur: bool = True,
                        extract_tables: bool = True,
                        extract_formulas: bool = False,
                        language: str = 'auto') -> Dict:
        """
        å…¨é¢å¤„ç†æ–‡æ¡£
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            auto_rotate: æ˜¯å¦è‡ªåŠ¨æ—‹è½¬
            remove_watermark: æ˜¯å¦å»é™¤æ°´å°
            enhance_blur: æ˜¯å¦å¢å¼ºæ¨¡ç³Šå›¾åƒ
            extract_tables: æ˜¯å¦æå–è¡¨æ ¼
            extract_formulas: æ˜¯å¦æå–å…¬å¼
            language: è¯­è¨€è®¾ç½®
        Returns:
            å¤„ç†ç»“æœ
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¤„ç†æ–‡æ¡£: {os.path.basename(file_path)}")
        print(f"{'='*60}\n")
        
        import fitz  # PyMuPDF
        
        doc = fitz.open(file_path)
        results = {
            'file_name': os.path.basename(file_path),
            'total_pages': len(doc),
            'pages': []
        }
        
        for page_num in range(len(doc)):
            print(f"\nå¤„ç†ç¬¬ {page_num + 1}/{len(doc)} é¡µ...")
            
            page = doc[page_num]
            
            # è½¬æ¢ä¸ºå›¾åƒ
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            img_data = pix.tobytes("png")
            image = Image.open(io.BytesIO(img_data))
            img_array = np.array(image)
            
            # è½¬æ¢é¢œè‰²ç©ºé—´ï¼ˆPILæ˜¯RGBï¼ŒOpenCVæ˜¯BGRï¼‰
            if len(img_array.shape) == 3:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            
            page_result = {
                'page_number': page_num + 1,
                'text': '',
                'tables': [],
                'formulas': [],
                'processing_steps': []
            }
            
            # 1. å›¾åƒé¢„å¤„ç†
            processed_image = img_array.copy()
            
            # æ£€æµ‹æ¨¡ç³Šåº¦
            blur_score = self.preprocessor.detect_blur(processed_image)
            if blur_score < 100 and enhance_blur:
                page_result['processing_steps'].append('æ¨¡ç³Šå¢å¼º')
                processed_image = self.preprocessor.enhance_blurry_image(processed_image)
            
            # è‡ªåŠ¨æ—‹è½¬
            if auto_rotate:
                page_result['processing_steps'].append('æ–¹å‘æ£€æµ‹ä¸æ—‹è½¬')
                processed_image = self.preprocessor.detect_and_rotate(processed_image)
            
            # å»æ°´å°
            if remove_watermark:
                page_result['processing_steps'].append('æ°´å°å»é™¤')
                processed_image = self.preprocessor.remove_watermark(processed_image, method='auto')
            
            # 2. è¡¨æ ¼æå–
            if extract_tables:
                tables = self.table_extractor.extract_table_with_merged_cells(
                    processed_image, 
                    page_num
                )
                page_result['tables'] = tables
            
            # 3. æ–‡æœ¬OCR
            ocr_results = self.multilang_ocr.ocr_with_language(processed_image, language)
            
            text_lines = []
            if ocr_results:
                for line in ocr_results:
                    if line and len(line) >= 2:
                        text = line[1][0]
                        confidence = line[1][1]
                        if confidence > 0.6:  # åªä¿ç•™é«˜ç½®ä¿¡åº¦ç»“æœ
                            text_lines.append(text)
            
            page_result['text'] = '\n'.join(text_lines)
            
            # 4. å…¬å¼æå–ï¼ˆå¯é€‰ï¼‰
            if extract_formulas:
                formulas = self.formula_extractor.extract_formulas(processed_image)
                page_result['formulas'] = formulas
            
            results['pages'].append(page_result)
            
            print(f"  âœ… å®Œæˆ - æå–æ–‡æœ¬: {len(text_lines)}è¡Œ, è¡¨æ ¼: {len(page_result['tables'])}ä¸ª")
        
        doc.close()
        
        print(f"\n{'='*60}")
        print(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼")
        print(f"{'='*60}\n")
        
        return results
    
    def export_results(self, results: Dict, output_path: str = None):
        """
        å¯¼å‡ºå¤„ç†ç»“æœ
        Args:
            results: å¤„ç†ç»“æœ
            output_path: è¾“å‡ºè·¯å¾„
        """
        if output_path is None:
            output_path = f"{results['file_name']}_ocr_results.json"
        
        import json
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        # åŒæ—¶ç”Ÿæˆå¯è¯»çš„æ–‡æœ¬ç‰ˆæœ¬
        text_output = output_path.replace('.json', '.txt')
        with open(text_output, 'w', encoding='utf-8') as f:
            f.write(f"æ–‡æ¡£: {results['file_name']}\n")
            f.write(f"æ€»é¡µæ•°: {results['total_pages']}\n")
            f.write("="*60 + "\n\n")
            
            for page in results['pages']:
                f.write(f"\nç¬¬ {page['page_number']} é¡µ\n")
                f.write("-"*60 + "\n")
                
                if page['processing_steps']:
                    f.write(f"å¤„ç†æ­¥éª¤: {', '.join(page['processing_steps'])}\n\n")
                
                if page['tables']:
                    f.write(f"[æ£€æµ‹åˆ° {len(page['tables'])} ä¸ªè¡¨æ ¼]\n\n")
                    for table in page['tables']:
                        f.write(table.get('markdown', '') + '\n\n')
                
                f.write(page['text'] + '\n\n')
        
        print(f"âœ… æ–‡æœ¬ç‰ˆæœ¬å·²ä¿å­˜åˆ°: {text_output}")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("=== é«˜çº§OCRç³»ç»Ÿæµ‹è¯• ===\n")
    
    print("ç³»ç»ŸåŠŸèƒ½:")
    print("  âœ… è‡ªåŠ¨æ—‹è½¬çº æ­£")
    print("  âœ… æ°´å°å»é™¤")
    print("  âœ… æ¨¡ç³Šå›¾åƒå¢å¼º")
    print("  âœ… å¤æ‚è¡¨æ ¼è¯†åˆ«ï¼ˆå«åˆå¹¶å•å…ƒæ ¼ï¼‰")
    print("  âœ… å¤šè¯­è¨€æ”¯æŒï¼ˆä¸­è‹±å¾·è¥¿ç­‰ï¼‰")
    print("  âœ… ç¹ä½“å­—è¯†åˆ«")
    print("  âœ… æ•°å­¦å…¬å¼æå–")
    print("\nä½¿ç”¨ç¤ºä¾‹:")
    print("""
    from advanced_ocr_system import ComprehensiveOCRSystem
    
    # åˆ›å»ºç³»ç»Ÿ
    ocr_system = ComprehensiveOCRSystem()
    
    # å¤„ç†æ–‡æ¡£
    results = ocr_system.process_document(
        'document.pdf',
        auto_rotate=True,
        remove_watermark=True,
        enhance_blur=True,
        extract_tables=True,
        extract_formulas=False,
        language='auto'  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
    )
    
    # å¯¼å‡ºç»“æœ
    ocr_system.export_results(results)
    """)

