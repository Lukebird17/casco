#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆOCRç³»ç»Ÿ - å……åˆ†åˆ©ç”¨PaddleOCR 3.0åŸç”Ÿèƒ½åŠ›
"""

import os
import sys
sys.path.insert(0, os.path.dirname(__file__))

import cv2
import numpy as np
from typing import Dict, List
from PIL import Image
import io
import fitz
import json


class SimpleOCRSystem:
    """ç®€åŒ–ç‰ˆOCRç³»ç»Ÿ - æ”¯æŒæœ¬åœ°å¼•æ“å’ŒGradioåœ¨çº¿API"""
    
    _instance = None
    _initialized = False
    
    # åœ¨çº¿APIé…ç½®ï¼ˆGradioåº”ç”¨ï¼‰
    API_URL = os.getenv('PADDLEOCR_API_URL', '')
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, use_api: bool = True):
        """
        åˆå§‹åŒ–OCRç³»ç»Ÿ - ä»…æ”¯æŒGradio APIæ¨¡å¼
        
        Args:
            use_api: æ˜¯å¦ä½¿ç”¨åœ¨çº¿APIï¼ˆå›ºå®šä¸ºTrueï¼Œä¿ç•™å‚æ•°ä»…ä¸ºå…¼å®¹æ€§ï¼‰
        """
        if SimpleOCRSystem._initialized:
            return
        
        print("ğŸš€ åˆå§‹åŒ–ç®€åŒ–ç‰ˆOCRç³»ç»Ÿ...")
        
        # æ£€æŸ¥APIé…ç½®
        if not self.API_URL:
            raise ValueError("âŒ API_URLæœªé…ç½®ï¼è¯·è®¾ç½®ç¯å¢ƒå˜é‡ PADDLEOCR_API_URL")
        
        print(f"  ğŸŒ ä½¿ç”¨Gradioåœ¨çº¿APIæ¨¡å¼")
        print(f"  ğŸ“ APIåœ°å€: {self.API_URL}")
        
        try:
            from gradio_client import Client
            self.gradio_client = Client(self.API_URL)
            print(f"  âœ… Gradioå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            raise ImportError("  âŒ gradio_clientæœªå®‰è£…ï¼è¯·è¿è¡Œ: pip install gradio_client")
        except Exception as e:
            raise RuntimeError(f"  âŒ Gradioå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        
        self.use_api = True
        self.ocr = None  # APIæ¨¡å¼ä¸éœ€è¦æœ¬åœ°å¼•æ“
        
        SimpleOCRSystem._initialized = True
        print("âœ… OCRç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    # ç§»é™¤æœ¬åœ°å¼•æ“åˆå§‹åŒ– - ä»…ä½¿ç”¨APIæ¨¡å¼
    
    def process_document(self, pdf_path: str, 
                   use_structure_analysis: bool = True,
                   extract_toc: bool = True) -> Dict:
        """
        å¤„ç†PDFæ–‡æ¡£ - ä½¿ç”¨Gradio API
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            use_structure_analysis: æ˜¯å¦ä½¿ç”¨ç»“æ„åˆ†æï¼ˆç‰ˆé¢åˆ†æ+è¡¨æ ¼è¯†åˆ«ï¼‰- APIè‡ªåŠ¨æ”¯æŒ
            extract_toc: æ˜¯å¦æå–ç›®å½•
        
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        
        """
        print(f"\n{'='*60}")
        print(f"å¤„ç†æ–‡æ¡£: {os.path.basename(pdf_path)}")
        print(f"{'='*60}\n")
        
        # ä»…ä½¿ç”¨APIæ¨¡å¼
        return self._process_with_api(pdf_path, extract_toc)
    
    def _process_with_api(self, pdf_path: str, extract_toc: bool) -> Dict:
        """ä½¿ç”¨Gradioåœ¨çº¿APIå¤„ç†æ–‡æ¡£ï¼ˆå¹¶è¡Œå¤„ç†å¤šé¡µï¼‰"""
        from gradio_client import handle_file
        import tempfile
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        print("ğŸŒ ä½¿ç”¨Gradio APIå¤„ç†...")
        print(f"  ğŸ“„ æ–‡ä»¶: {pdf_path}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "output"
        os.makedirs(output_dir, exist_ok=True)
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜æ”¾è½¬æ¢çš„å›¾ç‰‡
        temp_dir = tempfile.mkdtemp(prefix="pdf2img_")
        
        try:
            # ç¬¬1æ­¥ï¼šå°†PDFè½¬æ¢ä¸ºå›¾ç‰‡
            print(f"  ğŸ”„ å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡...")
            doc = fitz.open(pdf_path)
            total_pages = len(doc)
            print(f"  ğŸ“„ å…± {total_pages} é¡µ")
            
            base_name = os.path.splitext(os.path.basename(pdf_path))[0]
            img_paths = []
            
            # å…ˆè½¬æ¢æ‰€æœ‰é¡µé¢ä¸ºå›¾ç‰‡
            for page_num in range(total_pages):
                page = doc[page_num]
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2å€ç¼©æ”¾æé«˜è´¨é‡
                img_path = os.path.join(temp_dir, f"page_{page_num + 1}.png")
                pix.save(img_path)
                img_paths.append((page_num + 1, img_path))
            
            doc.close()
            print(f"  âœ… å›¾ç‰‡è½¬æ¢å®Œæˆ")
            
            # ç¬¬2æ­¥ï¼šå¹¶è¡Œè°ƒç”¨APIå¤„ç†æ‰€æœ‰å›¾ç‰‡
            print(f"  ğŸš€ å¹¶è¡Œå¤„ç† {total_pages} é¡µï¼ˆæœ€å¤šåŒæ—¶ {min(total_pages, 5)} ä¸ªè¯·æ±‚ï¼‰...")
            
            def process_page(page_info):
                """å¤„ç†å•ä¸ªé¡µé¢çš„å‡½æ•°"""
                page_num, img_path = page_info
                try:
                    result = self.gradio_client.predict(
                        fp=handle_file(img_path),
                        use_chart=True,         # å¯ç”¨å›¾è¡¨è§£æ
                        use_unwarping=True,     # å¯ç”¨æ–‡æ¡£çŸ«æ­£
                        use_orientation=True,   # å¯ç”¨æ–¹å‘åˆ†ç±»
                        api_name="/parse_doc_router"
                    )
                    
                    # resultæ˜¯ä¸€ä¸ªå…ƒç»„ï¼š(markdown_content, visualization_html, markdown_source)
                    markdown_content = result[0]
                    markdown_source = result[2]
                    text = markdown_content if markdown_content else markdown_source
                    
                    return {
                        'page_number': page_num,
                        'text': text,
                        'has_markdown': True,
                        'api_processed': True,
                        'success': True
                    }
                    
                except Exception as e:
                    return {
                        'page_number': page_num,
                        'text': '',
                        'has_markdown': False,
                        'api_processed': False,
                        'error': str(e),
                        'success': False
                    }
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            all_pages_text = [None] * total_pages  # é¢„åˆ†é…åˆ—è¡¨
            max_workers = min(5, total_pages)  # æœ€å¤š5ä¸ªå¹¶å‘è¯·æ±‚ï¼Œé¿å…è¿‡è½½
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_page = {executor.submit(process_page, page_info): page_info for page_info in img_paths}
                
                # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                completed = 0
                for future in as_completed(future_to_page):
                    result = future.result()
                    page_num = result['page_number']
                    all_pages_text[page_num - 1] = result  # æŒ‰é¡µç é¡ºåºå­˜å‚¨
                    
                    completed += 1
                    status = "âœ…" if result['success'] else "âš ï¸"
                    print(f"    {status} ç¬¬ {page_num}/{total_pages} é¡µå®Œæˆ ({completed}/{total_pages})")
            
            print(f"  âœ… æ‰€æœ‰é¡µé¢å¤„ç†å®Œæˆ")
            
            # åˆå¹¶æ‰€æœ‰é¡µé¢çš„æ–‡æœ¬
            combined_text = "\n\n---\n\n".join([p['text'] for p in all_pages_text if p['text']])
            
            # ä¿å­˜åˆå¹¶çš„Markdown
            md_filename = os.path.join(output_dir, f"{base_name}.md")
            with open(md_filename, "w", encoding="utf-8") as f:
                f.write(combined_text)
            print(f"  ğŸ’¾ Markdownå·²ä¿å­˜: {md_filename}")
            
            # æå–ç›®å½•ï¼ˆä»æœ¬åœ°PDFå…ƒæ•°æ®ï¼‰
            toc = []
            if extract_toc:
                try:
                    doc = fitz.open(pdf_path)
                    toc_raw = doc.get_toc()
                    if toc_raw:
                        toc = [{'level': item[0], 'title': item[1], 'page': item[2]} for item in toc_raw]
                        print(f"  ğŸ“‘ æå–åˆ° {len(toc)} ä¸ªç›®å½•é¡¹")
                    doc.close()
                except Exception as e:
                    print(f"  âš ï¸  ç›®å½•æå–å¤±è´¥: {e}")
            
            print(f"\nâœ… Gradio APIå¤„ç†å®Œæˆï¼")
            print(f"  ğŸ“Š å…±å¤„ç† {total_pages} é¡µ")
            print(f"  ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
            # print("process_api",all_pages_text)
            return {
                'file_name': os.path.basename(pdf_path),
                'total_pages': total_pages,
                'toc': toc,
                'pages': all_pages_text,
                'output_dir': output_dir,
                'api_processed': True,
                'combined_markdown': md_filename
            }
            
        except Exception as e:
            print(f"âŒ Gradio APIå¤„ç†å¤±è´¥: {e}")
            print(f"  ğŸ’¡ æç¤ºï¼šAPIå¯èƒ½åªæ”¯æŒå›¾ç‰‡æ ¼å¼")
            raise
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            import shutil
            try:
                shutil.rmtree(temp_dir)
            except:
                pass
    
    def _process_with_local(self, pdf_path: str, use_structure_analysis: bool = True, extract_toc: bool = True) -> Dict:
        """æœ¬åœ°å¤„ç†æ–¹æ³•å·²ç§»é™¤ - ä»…æ”¯æŒAPIæ¨¡å¼"""
        raise NotImplementedError("æœ¬åœ°å¤„ç†æ¨¡å¼å·²ç§»é™¤ï¼Œä»…æ”¯æŒGradio APIæ¨¡å¼ã€‚è¯·é…ç½®PADDLEOCR_API_URLç¯å¢ƒå˜é‡ã€‚")
    
    def _process_with_local_removed(self, pdf_path: str, use_structure_analysis: bool, extract_toc: bool) -> Dict:
        """ä½¿ç”¨æœ¬åœ°å¼•æ“å¤„ç†æ–‡æ¡£"""
        print("ğŸ’» ä½¿ç”¨æœ¬åœ°å¼•æ“å¤„ç†...")
        
        doc = fitz.open(pdf_path)
        results = {
            'file_name': os.path.basename(pdf_path),
            'total_pages': len(doc),
            'toc': [],
            'pages': []
        }
        
        # 1. æå–ç›®å½•ï¼ˆæ¥è‡ªPDFå…ƒæ•°æ®ï¼‰
        if extract_toc:
            toc = doc.get_toc()
            if toc:
                print(f"ğŸ“‘ æå–åˆ° {len(toc)} ä¸ªç›®å½•é¡¹")
                results['toc'] = [
                    {'level': item[0], 'title': item[1], 'page': item[2]}
                    for item in toc
                ]
        
        # 2. é€é¡µå¤„ç†
        for page_num in range(len(doc)):
            print(f"\nå¤„ç†ç¬¬ {page_num + 1}/{len(doc)} é¡µ...")
            page = doc[page_num]
            
            # è½¬ä¸ºå›¾åƒ
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            img_data = pix.tobytes("png")
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                tmp_path = tmp.name
                tmp.write(img_data)
            
            page_result = {
                'page_number': page_num + 1,
                'text': '',
                'tables': [],
                'layout': []
            }
            
            # 3. ä½¿ç”¨PPStructureV3è¿›è¡Œæ–‡æ¡£ç»“æ„åˆ†æ
            if use_structure_analysis and self.structure:
                try:
                    print("  ğŸ“„ PPStructureV3åˆ†ææ–‡æ¡£ç»“æ„...")
                    structure_result = self.structure.predict(input=tmp_path)
                    
                    text_parts = []
                    table_count = 0
                    
                    for res in structure_result:
                        # ä¿å­˜markdownæ ¼å¼ï¼ˆåŒ…å«è¡¨æ ¼å’Œæ–‡æœ¬ï¼‰
                        if hasattr(res, 'save_to_markdown'):
                            md_dir = f"output/page_{page_num + 1}"
                            os.makedirs(md_dir, exist_ok=True)
                            res.save_to_markdown(save_path=md_dir)
                        
                        # æå–æ–‡æœ¬
                        text = self._extract_text_from_result(res)
                        if text:
                            text_parts.append(text)
                        
                        # ç»Ÿè®¡è¡¨æ ¼
                        if hasattr(res, 'layout_parsing_result'):
                            layout = res.layout_parsing_result
                            if 'table' in str(layout).lower():
                                table_count += 1
                    
                    page_result['text'] = '\n'.join(text_parts)
                    
                    if table_count > 0:
                        print(f"  âœ… æ£€æµ‹åˆ° {table_count} ä¸ªè¡¨æ ¼")
                        page_result['tables'].append({'count': table_count, 'markdown_dir': md_dir})
                    
                    print(f"  âœ… æå–æ–‡æœ¬å†…å®¹")
                
                except Exception as e:
                    print(f"  âš ï¸  ç»“æ„åˆ†æå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(tmp_path)
            except:
                pass
            
            results['pages'].append(page_result)
        
        doc.close()
        
        print(f"\n{'='*60}")
        print(f"å¤„ç†å®Œæˆï¼")
        print(f"{'='*60}\n")
        
        return results
    
    def _extract_text_from_result(self, result):
        """ä»PaddleOCRç»“æœå¯¹è±¡ä¸­æå–æ–‡æœ¬"""
        try:
            # æ–¹æ³•1: ç›´æ¥è·å–textå±æ€§
            if hasattr(result, 'text'):
                return result.text
            
            # æ–¹æ³•2: ä»ocr_resultå±æ€§è·å–
            if hasattr(result, 'ocr_result'):
                ocr_res = result.ocr_result
                if isinstance(ocr_res, list):
                    return '\n'.join([str(item) for item in ocr_res])
            
            # æ–¹æ³•3: è½¬å­—ç¬¦ä¸²
            return str(result)
        except:
            return ""
    
    def export_results(self, results: Dict, output_path: str = None):
        """å¯¼å‡ºç»“æœ"""
        if output_path is None:
            output_path = f"output/{results['file_name']}_ocr.json"
        
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # ä¿å­˜JSON
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSONç»“æœ: {output_path}")
        
        # ä¿å­˜æ–‡æœ¬ç‰ˆæœ¬
        txt_path = output_path.replace('.json', '.txt')
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(f"æ–‡æ¡£: {results['file_name']}\n")
            f.write(f"æ€»é¡µæ•°: {results['total_pages']}\n")
            f.write("="*60 + "\n\n")
            
            # ç›®å½•
            if results['toc']:
                f.write("## ç›®å½•\n\n")
                for item in results['toc']:
                    indent = "  " * (item['level'] - 1)
                    f.write(f"{indent}- {item['title']} (ç¬¬{item['page']}é¡µ)\n")
                f.write("\n" + "="*60 + "\n\n")
            
            # é¡µé¢å†…å®¹
            for page in results['pages']:
                f.write(f"\nç¬¬ {page['page_number']} é¡µ\n")
                f.write("-"*60 + "\n")
                
                if page['tables']:
                    f.write(f"[æ£€æµ‹åˆ° {len(page['tables'])} ä¸ªè¡¨æ ¼]\n\n")
                
                f.write(page['text'] + '\n\n')
        
        print(f"âœ… æ–‡æœ¬ç»“æœ: {txt_path}")



if __name__ == "__main__":
    print("="*60)
    print("ç®€åŒ–ç‰ˆOCRç³»ç»Ÿ - åŸºäºPPStructureV3")
    print("="*60)
    print("\nâœ¨ æ ¸å¿ƒæŠ€æœ¯ï¼šPPStructureV3")
    print("   - æ–‡æ¡£ç»“æ„åˆ†æï¼ˆç‰ˆé¢å¸ƒå±€è¯†åˆ«ï¼‰")
    print("   - è¡¨æ ¼è¯†åˆ«ï¼ˆå«åˆå¹¶å•å…ƒæ ¼ï¼‰")
    print("   - æ–‡æœ¬OCRè¯†åˆ«ï¼ˆå¤šè¯­è¨€ï¼‰")
    print("   - è‡ªåŠ¨æ–¹å‘æ£€æµ‹å’Œçº æ­£")
    print("   - è‡ªåŠ¨æ–‡æ¡£ç•¸å˜çŸ«æ­£")
    print("\nğŸ“‹ åŠŸèƒ½ç‰¹æ€§:")
    print("  âœ… å¤šè¯­è¨€è¯†åˆ«ï¼ˆä¸­è‹±æ–‡ã€ç¹ä½“ç­‰ï¼‰")
    print("  âœ… ç‰ˆé¢åˆ†æï¼ˆæ ‡é¢˜ã€æ®µè½ã€è¡¨æ ¼ã€å›¾ç‰‡ï¼‰")
    print("  âœ… è¡¨æ ¼ç»“æ„è¯†åˆ«ï¼ˆå«åˆå¹¶å•å…ƒæ ¼ï¼‰")
    print("  âœ… æ–¹å‘æ£€æµ‹å’Œçº æ­£")
    print("  âœ… æ–‡æ¡£ç•¸å˜çŸ«æ­£")
    print("  âœ… ç›®å½•æå–ï¼ˆPDFå…ƒæ•°æ®ï¼‰")
    print("  âœ… è¾“å‡ºMarkdownæ ¼å¼")
    print("\nğŸ“ ä½¿ç”¨ç¤ºä¾‹:")
    print("""
from simple_ocr_system import SimpleOCRSystem

# åˆå§‹åŒ–ï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
ocr = SimpleOCRSystem()

# å¤„ç†æ–‡æ¡£
results = ocr.process_document(
    'document.pdf',
    use_structure_analysis=True,  # ä½¿ç”¨ç»“æ„åˆ†æ
    extract_toc=True              # æå–ç›®å½•
)

# å¯¼å‡ºç»“æœ
ocr.export_results(results)

# ç»“æœåŒ…å«ï¼š
# - æ–‡æœ¬å†…å®¹
# - è¡¨æ ¼ï¼ˆMarkdownæ ¼å¼ï¼‰
# - ç‰ˆé¢ç»“æ„
# - ç›®å½•ä¿¡æ¯
""")

