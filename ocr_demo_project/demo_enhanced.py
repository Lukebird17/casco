#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
@File    :   demo_enhanced.py
@Time    :   2025/11/16
@Desc    :   å¢å¼ºç‰ˆæ™ºèƒ½ä½“ä½¿ç”¨ç¤ºä¾‹
'''

from VectorBase import VectorStore
from LLM import OpenAIChat
from my_BGE_embedding import BGEEmbedding  # å¯¼å…¥ä½ åˆšå†™å¥½çš„BGEç±»
from enhanced_agent import EnhancedRAGAgent
import json
import os
import numpy as np

RESULTS_FILE = "enhanced_demo_results.json"

def convert(o):
    if isinstance(o, np.float32) or isinstance(o, np.float64):
        return float(o)
    if isinstance(o, np.int32) or isinstance(o, np.int64):
        return int(o)
    if isinstance(o, np.ndarray):
        return o.tolist()
    raise TypeError(f"Object of type {type(o).__name__} is not JSON serializable")

def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå¢å¼ºç‰ˆæ™ºèƒ½ä½“çš„ä½¿ç”¨"""
    
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘         å¢å¼ºç‰ˆæ™ºèƒ½ä½“ Demo                            â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    # 1. åŠ è½½å‘é‡æ•°æ®åº“
    print("ğŸ“‚ åŠ è½½å‘é‡æ•°æ®åº“...")
    vector_store = VectorStore()
    vector_store.load_vector('./storage_bge_hierarchical')
    print(f"âœ… åŠ è½½å®Œæˆï¼Œæ–‡æ¡£æ•°é‡: {len(vector_store.document)}\n")
    
    # 2. åˆå§‹åŒ–æ¨¡å‹
    print("ğŸ¤– åˆå§‹åŒ–æ¨¡å‹...")
    embedding = BGEEmbedding()
    llm = OpenAIChat()
    print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n")
    
    # 3. åˆ›å»ºå¢å¼ºç‰ˆæ™ºèƒ½ä½“
    print("ğŸš€ åˆ›å»ºå¢å¼ºç‰ˆæ™ºèƒ½ä½“...")
    agent = EnhancedRAGAgent(
        vector_store=vector_store,
        llm=llm,
        embedding=embedding,
        enable_tracking=True  # å¯ç”¨Tokenè¿½è¸ª
    )
    print("âœ… æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ\n")
    
    # 4. æµ‹è¯•é—®é¢˜
    test_questions = [
        "æ ¹æ®æ–‡æ¡£ã€Š2024_Communications-Based Train Controlã€‹ï¼Œå›¾ 5.11 æ‰€ç¤ºçš„ç½‘çŠ¶æ§åˆ¶å›è·¯ç»“æ„ï¼ŒATO å­ç³»ç»Ÿæ˜¯å¦‚ä½•å®ç°è‡ªèº«çš„æ§åˆ¶å›è·¯çš„ï¼Ÿè¯·é˜è¿°å…¶å¦‚ä½•è·å–è¾“å…¥ï¼ˆMessgliederï¼‰ï¼Œå¦‚ä½•å½¢æˆè½¦è¾†è½¨è¿¹ï¼ˆFahrzeugtrajektorieï¼‰ï¼Œä»¥åŠå¦‚ä½•å°†è½¨è¿¹ä½œä¸ºç›®æ ‡å€¼ä¼ é€’ç»™åˆ—è½¦çš„æ§åˆ¶è®¾å¤‡ï¼ˆSteuergerÃ¤t)"
        ]
    
    results = []
    if test_questions:
        question = test_questions[0]
        print(f"\n============================================================")
        print(f"é—®é¢˜: {question}")
        print(f"============================================================\n")
        
        try:
            # è°ƒç”¨æ™ºèƒ½ä½“ï¼Œè·å–ç»“æœ
            full_result_text = agent.query_with_full_features(question)
            
            # å­˜å‚¨å½“å‰é—®é¢˜çš„ç»“æœ
            results.append({
                "question_id": 1,  # å›ºå®šIDä¸º1
                "question": question,
                "answer": full_result_text,
                "status": "Success"
            })
            print(f"âœ… é—®é¢˜å¤„ç†æˆåŠŸã€‚")
            
        except Exception as e:
            # æ•è·é”™è¯¯ï¼Œè®°å½•ä¸‹æ¥
            print(f"âŒ é—®é¢˜å‘ç”Ÿé”™è¯¯ï¼Œæ— æ³•è·å–ç­”æ¡ˆ: {e}")
            results.append({
                "question_id": 1,  # å›ºå®šIDä¸º1
                "question": question,
                "answer": None,
                "status": f"Error: {str(e)}"
            })
            
        finally:
            # æ–°å¢/ä¿®æ”¹ï¼šå¤„ç†å®Œæ¯•åä¿å­˜ç»“æœ
            with open(RESULTS_FILE, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=4, default=convert)
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° {RESULTS_FILE}")

    print("\næ‰€æœ‰é—®é¢˜å¤„ç†å®Œæ¯•ã€‚")
    print("\n\næ‰€æœ‰é—®é¢˜å¤„ç†å®Œæ¯•ã€‚")
    
    
    # for i, question in enumerate(test_questions, 1):
    #     print(f"\n{'='*60}")
    #     print(f"é—®é¢˜ {i}: {question}")
    #     print(f"{'='*60}\n")
        
    #     # 5. æ‰§è¡ŒæŸ¥è¯¢ï¼ˆä½¿ç”¨å®Œæ•´å¢å¼ºåŠŸèƒ½ï¼‰
    #     result = agent.query_with_full_features(question)
        
    #     # 6. æ˜¾ç¤ºç­”æ¡ˆ
    #     print(f"\nâœ… ç­”æ¡ˆ:")
    #     print(f"{result['answer']}\n")
        
    #     # 7. æ˜¾ç¤ºæ¨ç†é“¾ï¼ˆå¯é€‰ï¼‰
    #     if result.get('reasoning_chain'):
    #         print("\n" + "="*60)
    #         print("æ¨ç†è¿‡ç¨‹:")
    #         print("="*60)
    #         print(result['reasoning_chain'].format_chain(detailed=False))
        
    #     # 8. æ˜¾ç¤ºTokenä½¿ç”¨æƒ…å†µ
    #     if result.get('token_usage'):
    #         print(f"\nğŸ“Š æœ¬æ¬¡æŸ¥è¯¢Tokenæ¶ˆè€—:")
    #         print(f"  â€¢ æ€»è®¡: {result['token_usage']['total_tokens']:,} tokens")
        
    #     # 9. æ ¼å¼åŒ–è¾“å‡ºï¼ˆç¬¦åˆç«èµ›è¦æ±‚ï¼‰
    #     formatted_output = agent.format_output(result, include_reasoning=False)
    #     results.append(formatted_output)
        
    #     print("\n" + "="*60)
    
    # # 10. ä¿å­˜ç»“æœ
    # print("\nğŸ’¾ ä¿å­˜ç»“æœ...")
    # final_output = {"items": results}
    # with open('enhanced_demo_results.json', 'w', encoding='utf-8') as f:
    #     json.dump(final_output, f, ensure_ascii=False, indent=2) # å†™å…¥ final_output
    # print("âœ… ç»“æœå·²ä¿å­˜åˆ°: enhanced_demo_results.json\n")
    # ...
    # 11. æ˜¾ç¤ºæ€§èƒ½æŠ¥å‘Š
    print("\n" + "="*60)
    print("æ€§èƒ½æŠ¥å‘Š")
    print("="*60)
    print(agent.get_performance_report())
    
    # 12. ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    print("\nğŸ’¾ ä¿å­˜è¯¦ç»†æŠ¥å‘Š...")
    agent.save_reports(output_dir='enhanced_reports')
    
    print("\nâœ… Demoå®Œæˆï¼")


def demo_advanced_features():
    """æ¼”ç¤ºé«˜çº§åŠŸèƒ½"""
    print("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘         é«˜çº§åŠŸèƒ½æ¼”ç¤º                                  â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    # æ¼”ç¤º1ï¼šTokenä¼˜åŒ–
    print("ã€åŠŸèƒ½1ï¼šTokenä¼˜åŒ–ã€‘")
    from token_tracker import TokenTracker
    
    tracker = TokenTracker()
    long_text = "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„æ–‡æœ¬ã€‚\n" * 500
    print(f"åŸå§‹æ–‡æœ¬: {len(long_text)} å­—ç¬¦, {tracker.count_tokens(long_text)} tokens")
    
    optimized = tracker.optimize_context(long_text, max_tokens=30000)
    # optimized = tracker.optimize_context(long_text, max_tokens=200)
    print(f"ä¼˜åŒ–å: {len(optimized)} å­—ç¬¦, {tracker.count_tokens(optimized)} tokens")
    print(f"èŠ‚çœ: {len(long_text) - len(optimized)} å­—ç¬¦\n")
    
    # æ¼”ç¤º2ï¼šæ¨ç†é“¾
    print("ã€åŠŸèƒ½2ï¼šæ¨ç†é“¾è®°å½•ã€‘")
    from reasoning_chain import ReasoningChain
    
    chain = ReasoningChain("æµ‹è¯•é—®é¢˜")
    chain.add_analysis_step("åˆ†æé—®é¢˜ç±»å‹")
    chain.add_retrieval_step("æ£€ç´¢ç›¸å…³æ–‡æ¡£")
    chain.add_inference_step("è¿›è¡Œé€»è¾‘æ¨ç†", confidence=0.9)
    chain.add_conclusion_step("å¾—å‡ºç»“è®º")
    
    print(chain.format_compact())
    print()
    
    # æ¼”ç¤º3ï¼šè¡¨æ ¼æå–
    print("ã€åŠŸèƒ½3ï¼šè¡¨æ ¼æå–ã€‘")
    from advanced_document_processor import AdvancedTableExtractor
    
    extractor = AdvancedTableExtractor()
    print("è¡¨æ ¼æå–å™¨å·²åˆå§‹åŒ–")
    print("æ”¯æŒpdfplumberå’ŒPyMuPDFä¸¤ç§æ–¹æ³•\n")
    
    # æ¼”ç¤º4ï¼šç‰ˆæœ¬å¯¹æ¯”
    print("ã€åŠŸèƒ½4ï¼šç‰ˆæœ¬å¯¹æ¯”ã€‘")
    from advanced_document_processor import VersionComparator
    
    comparator = VersionComparator()
    doc1 = "ç‰ˆæœ¬1çš„å†…å®¹\nåŒ…å«åŠŸèƒ½A\nåŒ…å«åŠŸèƒ½B"
    doc2 = "ç‰ˆæœ¬2çš„å†…å®¹\nåŒ…å«åŠŸèƒ½A\nåŒ…å«åŠŸèƒ½B\næ–°å¢åŠŸèƒ½C"
    
    comparison = comparator.compare_documents(doc1, doc2)
    print(f"ç›¸ä¼¼åº¦: {comparison['similarity_ratio']:.1%}")
    print(f"æ–°å¢: {comparison['added_lines']}è¡Œ")
    print(f"åˆ é™¤: {comparison['removed_lines']}è¡Œ\n")


if __name__ == "__main__":
    try:
        # è¿è¡Œä¸»Demo
        main()
        
        # è¿è¡Œé«˜çº§åŠŸèƒ½æ¼”ç¤º
        demo_advanced_features()
        
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        print("\næç¤ºï¼šè¯·ç¡®ä¿:")
        print("1. .envæ–‡ä»¶é…ç½®æ­£ç¡®")
        print("2. å‘é‡æ•°æ®åº“å·²æ„å»º (./storage_demo)")
        print("3. æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
        import traceback
        traceback.print_exc()

